{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evH6sjsxsKWE"
   },
   "source": [
    "# A pendulum video and autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "trlxwPDloKs5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import sys\n",
    "syspath = 'SindyPendulum/'\n",
    "if syspath not in sys.path:\n",
    "    sys.path.append(syspath)\n",
    "    \n",
    "from sindy_library import SINDyLibrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qNbEXw0Uo3zR",
    "outputId": "7eabf512-f2cf-4429-bc0e-9af2374ed4cd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VneYLUfl5bz"
   },
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pend(y, t,):\n",
    "    theta, omega = y\n",
    "    dydt = [omega, - np.sin(theta)]\n",
    "    return dydt\n",
    "\n",
    "def pend_damp(y, t,):\n",
    "    theta, omega = y\n",
    "    dydt = [omega, - np.sin(theta)-0.1*omega]\n",
    "    return dydt\n",
    "\n",
    "def select_ics(theta0,omegaics0):\n",
    "    ics = []\n",
    "    for i in range(n_ics):\n",
    "        for j in range(n_ics):\n",
    "            lim = (np.abs((omega0[j]**2)/2 - np.cos(theta0[i])))\n",
    "            if lim <  0.99 :\n",
    "                ics.append((theta0[i],omega0[j]))\n",
    "    return ics\n",
    "\n",
    "def wrap_to_pi(z):\n",
    "    z_mod = z % (2*np.pi)\n",
    "    subtract_m = (z_mod > np.pi) * (-2*np.pi)\n",
    "    return z_mod + subtract_m\n",
    "\n",
    "def image_gen(ics):\n",
    "    x = np.linspace(-1.5, 1.5, NX)\n",
    "    y = np.linspace(-1.5, 1.5, NY)\n",
    "    xx,yy = np.meshgrid(x, y)\n",
    "\n",
    "\n",
    "    data = np.empty([len(ics), len(t), len(x), len(y)],dtype = np.float32)\n",
    "    data2 = np.empty([len(ics), len(t), len(x), len(y)],dtype = np.float32)\n",
    "\n",
    "\n",
    "    for idx in range(len(ics)):\n",
    "        if(idx%100==0): print(idx,' su ', len(ics))\n",
    "        y0 = [ics[idx][0], ics[idx][1]]\n",
    "        sol = odeint(pend, y0,t)\n",
    "        theta = sol[:,0]\n",
    "        omega = sol[:,1]\n",
    "\n",
    "        temp = []\n",
    "        for i in range(len(theta)):\n",
    "            z = np.exp(- 20 *((xx - np.cos(theta[i] + np.pi/2))*(xx - \n",
    "                np.cos(theta[i] +np.pi/2))) - 20 * ((yy -np.sin(theta[i]+np.pi/2))*(yy -np.sin(theta[i]+np.pi/2))))\n",
    "            z = ((z - np.min(z))/(np.max(z)-np.min(z)))\n",
    "    \n",
    "            temp.append(z)\n",
    "        data[idx] = np.array(temp)\n",
    "        \n",
    "        temp = []\n",
    "        for i in range(len(omega)):            \n",
    "            exp = -20 * 2 * omega[i]*(np.cos(theta[i]+ np.pi/2) - np.sin(theta[i] + np.pi/2))\n",
    "            z = np.exp(- 20 *((xx - np.cos(theta[i] + np.pi/2))*(xx - \n",
    "                np.cos(theta[i] +np.pi/2))) - 20 * ((yy -np.sin(theta[i]+np.pi/2))*(yy -np.sin(theta[i]+np.pi/2))))\n",
    "            z = z * exp\n",
    "            z = ((z - np.min(z))/(np.max(z)-np.min(z)))\n",
    "            temp.append(z)\n",
    "        data2[idx] = np.array(temp)\n",
    "        \n",
    "    return data,data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  su  3724\n",
      "100  su  3724\n",
      "200  su  3724\n",
      "300  su  3724\n",
      "400  su  3724\n",
      "500  su  3724\n",
      "600  su  3724\n",
      "700  su  3724\n",
      "800  su  3724\n",
      "900  su  3724\n",
      "1000  su  3724\n",
      "1100  su  3724\n",
      "1200  su  3724\n",
      "1300  su  3724\n",
      "1400  su  3724\n",
      "1500  su  3724\n",
      "1600  su  3724\n",
      "1700  su  3724\n",
      "1800  su  3724\n",
      "1900  su  3724\n",
      "2000  su  3724\n",
      "2100  su  3724\n",
      "2200  su  3724\n",
      "2300  su  3724\n",
      "2400  su  3724\n",
      "2500  su  3724\n",
      "2600  su  3724\n",
      "2700  su  3724\n",
      "2800  su  3724\n",
      "2900  su  3724\n",
      "3000  su  3724\n",
      "3100  su  3724\n",
      "3200  su  3724\n",
      "3300  su  3724\n",
      "3400  su  3724\n",
      "3500  su  3724\n",
      "3600  su  3724\n",
      "3700  su  3724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(186200, 729)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ics = 80\n",
    "    \n",
    "#COSTANTI e PARAMETRI\n",
    "ta = 0.\n",
    "tb = 5.\n",
    "dt = 0.1\n",
    "# tb = 10\n",
    "# dt = 0.1\n",
    "NX = 27\n",
    "NY = 27\n",
    "\n",
    "\n",
    "t = np.arange(ta, tb ,dt)\n",
    "theta0 = np.linspace(-np.pi,np.pi,n_ics)\n",
    "omega0 = np.linspace(-2.1, 2.1,n_ics)\n",
    "\n",
    "ics = select_ics(theta0,omega0)\n",
    "data,data2 = image_gen(ics)\n",
    "\n",
    "\n",
    "#questo reshape serve per mandare al autoencoder delle immagini flat\n",
    "#TODO verifica che sia corretto questo rehsape --> dovrebb essere ok fatto prova su colab\n",
    "X = data.reshape((len(ics) * len(t),NX * NY))\n",
    "Xdot = data2.reshape((len(ics) * len(t),NX * NY))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fa3bc3d89e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(X[123].reshape((51,51)))\n",
    "plt.imshow(X[123].reshape((27,27)))\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fa26f409668>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xdot[123].reshape((27,27)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UW2N4TZTbYsO",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([186200, 729]), torch.Size([186200, 729]), torch.float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.from_numpy(X).float().to(device)\n",
    "Xdot = torch.from_numpy(Xdot).float().to(device)\n",
    "X.shape, Xdot.shape, X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167580, 18620)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size = round(X.shape[0] * 0.1)\n",
    "train_size = X.shape[0] - val_size\n",
    "train_size, val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "B2vYJ447_sxQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "my_dataset = TensorDataset(X,Xdot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_subset, val_subset = torch.utils.data.random_split(my_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_subset, shuffle=True, batch_size=batch_size)\n",
    "val_loader   = DataLoader(val_subset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lRG3Ea4CWWl"
   },
   "source": [
    "# Network\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "5ZSdKOTO8dFN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size,latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,32)\n",
    "        self.fc4 = nn.Linear(32,latent_dim)\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            print(m)\n",
    "            if isinstance(m, nn.Linear):\n",
    "                #nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))   \n",
    "        x = torch.relu(self.fc4(x))\n",
    "        return x \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size,latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim,32)\n",
    "        self.fc2 = nn.Linear(32,64)\n",
    "        self.fc3 = nn.Linear(64,128)\n",
    "        self.fc4 = nn.Linear(128,input_size)\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))   \n",
    "        x = torch.relu(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                #nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(input_size,latent_dim)\n",
    "        self.decoder = Decoder(input_size,latent_dim)\n",
    "        self.SINDyLibrary = SINDyLibrary(\n",
    "            device=device,\n",
    "            latent_dim=latent_dim,\n",
    "            include_biases=True,\n",
    "            include_states=True,\n",
    "            include_sin=True,\n",
    "            include_cos=True,\n",
    "            include_multiply_pairs=False, #non ho capito cosa é ma conta due volte le coppie  \n",
    "            poly_order=2,\n",
    "            include_sqrt=False,\n",
    "            include_inverse=False,\n",
    "            include_sign_sqrt_of_diff=False)\n",
    "        \n",
    "\n",
    "        self.XI = nn.Parameter(torch.full((self.SINDyLibrary.number_candidate_functions,latent_dim),1.,dtype = torch.float32,requires_grad=True,device = device))\n",
    "\n",
    "        self.XI_coefficient_mask = torch.ones((self.SINDyLibrary.number_candidate_functions,latent_dim),dtype = torch.float32, device=device)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        learning_rate = 1e-4\n",
    "        #return torch.optim.SGD(self.parameters(), lr=learning_rate)\n",
    "        return torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "    def t_derivative(self,input, xdot, weights, biases, activation='sigmoid'):\n",
    "        \"\"\"\n",
    "        Compute the first order time derivatives by propagating through the network.\n",
    "        da[l]dt = xdot * da[l]dx = xdot * product(g'(w[l]a[l-1] + b[l])* w[l])\n",
    "        Arguments:\n",
    "            input - 2D tensorflow array, input to the network. Dimensions are number of time points\n",
    "            by number of state variables.\n",
    "            xdot - First order time derivatives of the input to the network. quello che conosciamo\n",
    "            weights - List of tensorflow arrays containing the network weights\n",
    "            biases - List of tensorflow arrays containing the network biases\n",
    "            activation - String specifying which activation function to use. Options are\n",
    "            'elu' (exponential linear unit), 'relu' (rectified linear unit), 'sigmoid',\n",
    "            or linear.\n",
    "\n",
    "        Returns:\n",
    "            dadt - Tensorflow array, first order time derivatives of the network output.\n",
    "        \"\"\"\n",
    "        a   = input\n",
    "        dadt = xdot #per le condizioni iniziali\n",
    "\n",
    "        if activation == 'sigmoid':\n",
    "            for i in range(len(weights) - 1):\n",
    "                z = torch.matmul(a, weights[i].T) + biases[i]\n",
    "                a = torch.sigmoid(z)\n",
    "                gprime = a * (1-a)\n",
    "                dadt = gprime * torch.matmul(dadt, weights[i].T)\n",
    "            dadt = torch.matmul(dadt, weights[-1].T) #fuori dal ciclo bisogna ancora moltiplicare per i pesi dell ultimo livello\n",
    "            \n",
    "        elif activation == 'relu':\n",
    "            for i in range(len(weights) - 1):\n",
    "                z = torch.matmul(a, weights[i].T) + biases[i]\n",
    "                a = torch.relu(z)\n",
    "                dadt = (z > 0).float() * torch.matmul(dadt, weights[i].T)    \n",
    "            dadt = torch.matmul(dadt, weights[-1].T) #fuori dal ciclo bisogna ancora moltiplicare per i pesi dell ultimo livello\n",
    "        return dadt #nel caso che ci serve dadt sará l output dell encoder ossia le latent variables!\n",
    "\n",
    "    \n",
    "    \n",
    "    def compute_quantities(self,x,xdot):\n",
    "    \n",
    "        z = self.encoder(x)\n",
    "        xtilde = self.decoder(z)\n",
    "\n",
    "        theta = self.SINDyLibrary.transform(z) \n",
    "        zdot_hat = torch.matmul(theta, self.XI_coefficient_mask * self.XI)\n",
    "        \n",
    "        encoder_parameters = list(self.encoder.parameters())\n",
    "        encoder_weight_list = [w for w in encoder_parameters if len(w.shape) == 2]\n",
    "        encoder_biases_list = [b for b in encoder_parameters if len(b.shape) == 1]\n",
    "        zdot = self.t_derivative(x, xdot, encoder_weight_list, encoder_biases_list, activation='sigmoid')                                               \n",
    "\n",
    "        #print(\"propagazione sul decoder\")\n",
    "        decoder_parameters = list(self.decoder.parameters())\n",
    "        decoder_weight_list = [w for w in decoder_parameters if len(w.shape) == 2]\n",
    "        decoder_biases_list = [b for b in decoder_parameters if len(b.shape) == 1]\n",
    "        xtildedot = self.t_derivative(z, zdot_hat, decoder_weight_list, decoder_biases_list, activation='sigmoid')    \n",
    "        \n",
    "        return xtilde, xtildedot, z, zdot, zdot_hat\n",
    "\n",
    "    def loss_function(self, x, xdot, xtilde, xtildedot, zdot, zdot_hat,XI):\n",
    "        mse = nn.MSELoss()\n",
    "        alpha1 = 5e-4\n",
    "        alpha2 = 5e-5\n",
    "        alpha3 = 1e-5\n",
    "\n",
    "\n",
    "        loss = {}\n",
    "        loss['recon_loss'] = mse(x, xtilde) #errore di ricostruzione \n",
    "        loss ['sindy_loss_x'] = mse(xdot, xtildedot) \n",
    "        loss ['sindy_loss_z'] = mse(zdot, zdot_hat) \n",
    "        loss['sindy_regular_loss'] = torch.sum(torch.abs(XI)) #norma L1 degli XI\n",
    "        loss['tot'] = loss['recon_loss'] + alpha1*loss['sindy_loss_x'] + alpha2*loss['sindy_loss_z'] + alpha3*loss['sindy_regular_loss']\n",
    "        tot = loss['tot']\n",
    "        return tot, loss\n",
    "    \n",
    "    def forward(self, x, xdot):\n",
    "        return self.compute_quantities(x, xdot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "c4mBzZuzxPYP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_size = X.shape[1]\n",
    "latent_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "sOuh7zJeoRmH",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (fc1): Linear(in_features=729, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Linear(in_features=729, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(input_size,latent_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "8r_OGkXz2Mgl",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.SINDyLibrary.number_candidate_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.SINDyLibrary.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZqwZy2XmMum"
   },
   "source": [
    "# Parameters and Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "zrBLCBxXTPaa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sequential_threshold(t):\n",
    "    if (t % seq_thres == 0 and t>1):\n",
    "        model.XI_coefficient_mask = torch.abs(model.XI) > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(t):\n",
    "    if SAVE == True:\n",
    "        if t % saving_rate == 0 and t > 0:\n",
    "            print('salvataggio a ',t,\"epoche\")\n",
    "            f1 = path + 'model' + '_' + str(t) + 'epochs' + '.pt'\n",
    "            torch.save({\n",
    "            'epoch': t,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': model.configure_optimizers().state_dict(),\n",
    "            'loss': model.loss_function,\n",
    "            'sindy_coefficients': model.XI,\n",
    "            'coefficient_mask' : model.XI_coefficient_mask\n",
    "            }, f1)\n",
    "            \n",
    "            XI = model.XI.cpu().detach().numpy()\n",
    "            np.save(path + 'model' + '_' + str(t) + 'epochs' + '.npy',XI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_model(t):\n",
    "    f = open(path + 'model_equation' + '_' + str(t) + '.txt', 'w')\n",
    "    coefficient_mask = model.XI_coefficient_mask.cpu().detach().numpy()\n",
    "    XI = model.XI.cpu().detach().numpy()\n",
    "    feature_list = model.SINDyLibrary.get_feature_names()\n",
    "    for j in range(latent_dim):\n",
    "        for i in range(len(feature_list)-1):\n",
    "            coeff = XI[i][j] * coefficient_mask[i][j]\n",
    "            if  abs(coeff) >= 0.1 and coeff != 0:\n",
    "                #print(f\"dz{j} = {coeff:.4f} {feature_list[i]}\")\n",
    "                f.write(f\"dz{j} = {coeff:.4f} {feature_list[i]}\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training step for one epoch\n",
    "def train_step(loss_list):\n",
    "        \n",
    "    #queste serve per le loss di ogni batch\n",
    "    loss_epoch = {}\n",
    "    loss_epoch['recon_loss'] = []\n",
    "    loss_epoch['sindy_loss_x'] = []\n",
    "    loss_epoch['sindy_loss_z'] = []\n",
    "    loss_epoch['sindy_regular_loss'] = []\n",
    "    loss_epoch['tot'] = []\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (X,Xdot) in enumerate (train_loader):\n",
    "        X.to(device) #per passarlo alla gpu\n",
    "        Xdot.to(device)\n",
    "        #forward pass \n",
    "        xtilde, xtildedot, z, zdot, zdot_hat = model(X,Xdot)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer = model.configure_optimizers()\n",
    "        loss, loss_dict = model.loss_function(X, Xdot, xtilde, xtildedot, zdot, zdot_hat,model.XI)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for key in loss_epoch.keys():\n",
    "            loss_epoch[key].append(loss_dict[key].item())\n",
    "        \n",
    "        \n",
    "    for key in loss_epoch.keys():\n",
    "            loss_list[key].append(sum(loss_epoch[key])/len(loss_epoch[key]))\n",
    "            \n",
    "    del loss_epoch,loss_dict,xtilde, xtildedot, z, zdot, zdot_hat,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(loss_val_list):\n",
    "    loss_val_epoch = []\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "    for batch, (X,Xdot) in enumerate (val_loader):\n",
    "        X.to(device) #per passarlo alla gpu\n",
    "        Xdot.to(device)\n",
    "        #forward pass \n",
    "        xtilde, xtildedot, z, zdot, zdot_hat = model(X,Xdot)\n",
    "        # validation loss \n",
    "        loss, _ = model.loss_function(X, Xdot, xtilde, xtildedot, zdot, zdot_hat,model.XI)\n",
    "        loss_val_epoch.append(loss.item())\n",
    "        del  xtilde, xtildedot, z, zdot, zdot_hat,loss\n",
    "\n",
    "    loss_val_list.append(sum(loss_val_epoch)/len(loss_val_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_loss(t):\n",
    "    if t % loss_rate == 0:\n",
    "        print()\n",
    "        print(f\"Epoch {t}\\n-------------------------------\")\n",
    "        for key in loss_list.keys():\n",
    "            temp = loss_list[key]\n",
    "            print(f'{key} of epoch {t}: {temp[-1]:.3e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION = False\n",
    "SAVE = True\n",
    "\n",
    "epochs = 2000\n",
    "path = '../model_zero/'\n",
    "\n",
    "seq_thres = 100   # numero epoche ogni quanto fare seq thres\n",
    "\n",
    "equation_rate = 100 #print delle equazioni trovate\n",
    "\n",
    "saving_rate = 100 # numero epoche in cui salvo il modello e gli XI\n",
    "\n",
    "loss_rate = 50  #print delle loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n",
      "epoch: 10\n",
      "epoch: 11\n",
      "epoch: 12\n",
      "epoch: 13\n",
      "epoch: 14\n",
      "epoch: 15\n",
      "epoch: 16\n",
      "epoch: 17\n",
      "epoch: 18\n",
      "epoch: 19\n",
      "epoch: 20\n",
      "epoch: 21\n",
      "epoch: 22\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-3c7fa7c00f1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_val_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-dd3d45620200>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(loss_list)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mXdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mxtilde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtildedot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzdot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzdot_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXdot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-c972611cb3e2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xdot)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxdot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_quantities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxdot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-c972611cb3e2>\u001b[0m in \u001b[0;36mcompute_quantities\u001b[0;34m(self, x, xdot)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mxtilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSINDyLibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mzdot_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXI_coefficient_mask\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SindyPendulum/sindy_library.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcand_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcand_func\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_functions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SindyPendulum/sindy_library.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcand_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcand_func\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_functions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SindyPendulum/sindy_library.py\u001b[0m in \u001b[0;36mpoly_deg_2\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_list = {}\n",
    "loss_list['recon_loss'] = []\n",
    "loss_list['sindy_loss_x'] = []\n",
    "loss_list['sindy_loss_z'] = []\n",
    "loss_list['sindy_regular_loss'] = []\n",
    "loss_list['tot'] = []\n",
    "loss_val_list = []\n",
    "\n",
    "\n",
    "while t <= epochs:\n",
    "    print(\"epoch:\",t)\n",
    "    train_step(loss_list)\n",
    "    \n",
    "    validation_step(loss_val_list)\n",
    "    \n",
    "    print_loss(t)\n",
    "\n",
    "    save_model(t)\n",
    "    \n",
    "    sequential_threshold(t)\n",
    "    \n",
    "    if t % equation_rate == 0 and t>1:\n",
    "        print_model(t)\n",
    "        data = pd.DataFrame.from_dict(loss_list)\n",
    "        data.to_csv(path + 'data_'+str(t)+'epochs'+'.csv')\n",
    "    t = t + 1\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.1271e-05,  6.5599e-03,  1.2202e-02,  1.4431e-04,  4.7406e-05,\n",
       "         -2.7708e-05,  1.7113e-05,  7.5515e-05,  1.9454e-04,  6.2652e-05],\n",
       "        [ 1.7395e-04, -2.7082e-04, -1.1467e-04, -7.6832e-05, -4.4830e-05,\n",
       "         -9.1452e-05,  9.5787e-05,  7.2177e-05,  1.0421e-04, -3.8364e-05],\n",
       "        [-7.4720e-05, -7.4709e-05, -7.4708e-05, -7.4714e-05, -7.4712e-05,\n",
       "         -7.4666e-05, -7.4711e-05, -7.4720e-05, -7.4717e-05, -7.4721e-05],\n",
       "        [-7.5907e-05, -7.3959e-05, -7.3964e-05, -7.7195e-05, -7.6877e-05,\n",
       "         -7.7212e-05, -7.5719e-05, -7.6289e-05, -7.6517e-05, -7.6685e-05],\n",
       "        [ 6.9510e-05,  3.4857e-05, -3.0195e-05,  8.7834e-05, -9.5061e-05,\n",
       "          7.2512e-05,  6.1618e-05,  3.4625e-05,  7.1275e-05, -3.4970e-05],\n",
       "        [ 8.1364e-05,  9.5410e-04,  9.9953e-04,  1.4610e-05, -8.3536e-05,\n",
       "         -1.4518e-05,  3.1336e-05,  1.5536e-04,  2.4264e-05, -6.7915e-05],\n",
       "        [ 1.2692e-04,  1.0753e-04,  1.4447e-04, -9.9059e-05,  3.0817e-05,\n",
       "          7.3508e-05,  1.6246e-04,  3.5435e-06,  1.3030e-04, -7.5003e-05],\n",
       "        [-5.1395e-05,  1.5293e-05, -8.5407e-05, -7.2263e-05, -6.8403e-05,\n",
       "         -7.3989e-05, -8.5157e-06, -5.7658e-05, -6.1659e-05, -6.6865e-05],\n",
       "        [-7.6816e-05,  4.3322e-04,  3.4226e-04,  3.4105e-05, -9.2413e-05,\n",
       "          1.1993e-05, -5.2156e-05, -4.7456e-05, -9.4890e-05, -3.0029e-05],\n",
       "        [ 5.8771e-05, -6.0349e-05, -1.1675e-04,  9.2062e-05, -9.1373e-05,\n",
       "          8.0522e-05, -4.8697e-05, -5.9179e-05,  5.8273e-05,  8.2711e-05],\n",
       "        [ 7.7199e-05,  5.9271e-04,  5.3503e-04,  1.8083e-05,  3.9083e-05,\n",
       "         -1.5371e-05,  6.6418e-05, -8.1307e-05, -5.6729e-05,  3.6983e-05],\n",
       "        [-9.1056e-05,  2.0806e-04,  1.3818e-04, -1.7639e-05, -4.8394e-05,\n",
       "          1.6856e-05, -1.6941e-04, -1.8490e-04, -5.5423e-05, -9.1157e-05],\n",
       "        [-7.4085e-05, -7.4083e-05, -7.4080e-05, -7.4061e-05, -7.4075e-05,\n",
       "         -7.3967e-05, -7.4089e-05, -7.4084e-05, -7.4080e-05, -7.4085e-05],\n",
       "        [-7.3403e-05, -7.5293e-05, -7.5018e-05, -7.1948e-05, -7.2000e-05,\n",
       "         -7.2867e-05, -7.3596e-05, -7.2093e-05, -7.2229e-05, -7.2168e-05],\n",
       "        [ 8.5927e-05, -6.7432e-05,  9.0599e-06,  9.0122e-05,  6.6833e-05,\n",
       "          9.7680e-05, -7.5165e-05,  1.0447e-06, -3.2657e-05,  4.3966e-05],\n",
       "        [-3.4420e-05, -1.1607e-03, -1.0246e-03,  3.5048e-05,  2.9952e-05,\n",
       "          5.0927e-05, -9.8319e-05, -9.9020e-05, -1.4281e-04,  4.3479e-06],\n",
       "        [-8.9947e-05, -8.0780e-05, -1.3222e-05, -4.1810e-05,  7.2323e-05,\n",
       "         -7.1148e-05, -7.8046e-05, -8.6050e-05, -1.7920e-04,  4.5922e-05],\n",
       "        [-8.2232e-05, -6.0698e-05, -9.2784e-05, -7.0402e-05, -7.4066e-05,\n",
       "         -7.2649e-05,  4.4856e-05, -7.8152e-05, -7.9289e-05, -7.7662e-05],\n",
       "        [-4.0060e-05, -4.5709e-04, -4.4435e-04, -6.6123e-06,  7.1588e-05,\n",
       "         -5.6956e-05,  9.1220e-05,  2.8438e-07,  9.5524e-05, -1.2121e-05],\n",
       "        [ 6.1881e-05,  7.2849e-05,  1.4449e-04,  5.7836e-05,  3.6931e-05,\n",
       "          6.6925e-05, -2.8077e-05, -3.2314e-05,  8.6387e-05,  2.2073e-05],\n",
       "        [ 4.8224e-05, -6.5787e-04, -5.3891e-04,  1.2024e-05, -7.3532e-05,\n",
       "         -8.5940e-05, -3.7003e-05,  8.5972e-05,  2.0558e-05,  2.9790e-06],\n",
       "        [ 6.8338e-05,  1.7250e-03,  6.5237e-03,  1.4830e-05,  1.3840e-04,\n",
       "         -6.5161e-05,  8.4546e-05,  2.9411e-05,  7.8158e-05,  3.0406e-05],\n",
       "        [ 8.5856e-06,  6.5566e-03,  1.2200e-02,  1.4437e-04,  2.4280e-05,\n",
       "         -3.5523e-05,  9.9546e-06,  7.5497e-05,  1.9486e-04,  7.2042e-05],\n",
       "        [ 1.0662e-05,  6.8905e-03,  1.2305e-02,  1.4352e-04,  2.3287e-05,\n",
       "         -2.7967e-05,  3.2408e-05,  1.6249e-04,  1.9501e-04,  7.6577e-05],\n",
       "        [ 1.3346e-04,  1.7703e-03,  6.7659e-03,  3.6649e-05,  1.4430e-04,\n",
       "         -2.6972e-06,  1.9260e-04,  1.7579e-04,  1.2053e-04,  1.5535e-04],\n",
       "        [ 1.3172e-04, -1.4682e-04,  1.0643e-03,  2.3325e-05,  1.2808e-04,\n",
       "         -7.4446e-05,  1.2508e-04,  1.5155e-04,  1.2755e-04,  7.8576e-05],\n",
       "        [ 4.1060e-05,  6.3622e-04,  1.2673e-03,  1.6582e-04,  1.9795e-04,\n",
       "         -9.3075e-05,  1.4130e-04,  4.6208e-05,  1.6298e-04,  3.8057e-05],\n",
       "        [ 1.1270e-04,  7.4606e-03,  1.3715e-02,  1.8340e-04,  1.1282e-04,\n",
       "          6.2023e-05,  2.2952e-05,  1.7869e-05,  1.0930e-04,  9.1656e-05],\n",
       "        [ 8.6914e-05,  2.3054e-03,  8.1205e-03,  1.9471e-04,  1.6519e-04,\n",
       "          5.9990e-05,  4.7564e-05,  1.6569e-04,  6.6873e-05,  7.8020e-05],\n",
       "        [ 2.9784e-05,  4.5932e-03,  1.0835e-02,  1.9276e-04,  1.5042e-04,\n",
       "          5.3844e-05,  1.7838e-04,  7.4415e-05,  5.0938e-05,  6.4061e-05],\n",
       "        [ 1.2342e-04, -7.3927e-05,  3.9796e-03,  6.9846e-05,  9.9050e-05,\n",
       "         -9.2727e-05,  8.4802e-05,  5.5663e-05,  1.3578e-04,  5.6422e-05],\n",
       "        [-2.7950e-05,  1.8879e-05,  1.5458e-04, -6.7623e-05, -6.0522e-05,\n",
       "         -7.1909e-05, -1.8702e-05, -4.0083e-05, -4.7478e-05, -5.6710e-05],\n",
       "        [-7.4614e-05, -7.4614e-05, -7.4614e-05, -7.4614e-05, -7.4614e-05,\n",
       "         -7.4614e-05, -7.4614e-05, -7.4614e-05, -7.4614e-05, -7.4614e-05],\n",
       "        [-7.5446e-05, -7.5441e-05, -7.5441e-05, -7.5447e-05, -7.5446e-05,\n",
       "         -7.5388e-05, -7.5444e-05, -7.5445e-05, -7.5446e-05, -7.5446e-05],\n",
       "        [-7.4607e-05, -7.4606e-05, -7.4606e-05, -7.4607e-05, -7.4606e-05,\n",
       "         -7.4607e-05, -7.4607e-05, -7.4606e-05, -7.4607e-05, -7.4607e-05],\n",
       "        [-5.5155e-05,  6.4075e-05, -3.5816e-05, -7.1716e-05, -6.8441e-05,\n",
       "         -7.3714e-05, -5.2036e-05, -5.9613e-05, -6.2641e-05, -6.6493e-05],\n",
       "        [-6.5172e-05, -4.7899e-05,  8.1640e-05, -7.3086e-05, -7.1460e-05,\n",
       "         -7.3939e-05, -6.3744e-05, -6.7188e-05, -6.8736e-05, -7.0525e-05],\n",
       "        [-7.4438e-05, -7.4226e-05, -7.4217e-05, -7.4573e-05, -7.4538e-05,\n",
       "         -7.4594e-05, -7.4405e-05, -7.4481e-05, -7.4511e-05, -7.4540e-05],\n",
       "        [-6.2637e-05, -2.9499e-05, -2.6610e-05, -7.3448e-05, -7.1242e-05,\n",
       "         -7.4542e-05, -6.0598e-05, -6.5471e-05, -6.7392e-05, -6.9953e-05],\n",
       "        [-5.7233e-05, -9.2860e-05,  9.8738e-06, -7.2239e-05, -6.9422e-05,\n",
       "         -7.3942e-05, -5.4628e-05, -6.1513e-05, -6.4223e-05, -6.7819e-05],\n",
       "        [-7.3698e-05, -6.9711e-05, -6.9626e-05, -7.5713e-05, -7.5313e-05,\n",
       "         -7.5923e-05, -7.3370e-05, -7.4236e-05, -7.4616e-05, -7.5108e-05],\n",
       "        [-7.4612e-05, -7.4612e-05, -7.4612e-05, -7.4613e-05, -7.4613e-05,\n",
       "         -7.4614e-05, -7.4612e-05, -7.4613e-05, -7.4612e-05, -7.4613e-05],\n",
       "        [-7.4616e-05, -7.4616e-05, -7.4615e-05, -7.4612e-05, -7.4613e-05,\n",
       "         -7.4613e-05, -7.4611e-05, -7.4612e-05, -7.4613e-05, -7.4616e-05],\n",
       "        [-7.4614e-05, -7.4616e-05, -7.4615e-05, -7.4612e-05, -7.4612e-05,\n",
       "         -7.4613e-05, -7.4612e-05, -7.4614e-05, -7.4613e-05, -7.4613e-05],\n",
       "        [-7.4613e-05, -7.4615e-05, -7.4614e-05, -7.4613e-05, -7.4613e-05,\n",
       "         -7.4613e-05, -7.4614e-05, -7.4613e-05, -7.4613e-05, -7.4613e-05],\n",
       "        [-7.4613e-05, -7.4613e-05, -7.4614e-05, -7.4613e-05, -7.4612e-05,\n",
       "         -7.4613e-05, -7.4613e-05, -7.4613e-05, -7.4613e-05, -7.4613e-05],\n",
       "        [-7.4651e-05, -7.4656e-05, -7.4660e-05, -7.4615e-05, -7.4619e-05,\n",
       "         -7.4612e-05, -7.4642e-05, -7.4643e-05, -7.4629e-05, -7.4647e-05],\n",
       "        [-7.4613e-05, -7.4614e-05, -7.4613e-05, -7.4612e-05, -7.4612e-05,\n",
       "         -7.4613e-05, -7.4611e-05, -7.4612e-05, -7.4611e-05, -7.4611e-05],\n",
       "        [-7.4614e-05, -7.4614e-05, -7.4614e-05, -7.4614e-05, -7.4614e-05,\n",
       "         -7.4614e-05, -7.4614e-05, -7.4614e-05, -7.4614e-05, -7.4614e-05],\n",
       "        [-7.4918e-05, -7.4920e-05, -7.4922e-05, -7.4910e-05, -7.4913e-05,\n",
       "         -7.4911e-05, -7.4914e-05, -7.4915e-05, -7.4913e-05, -7.4912e-05],\n",
       "        [-7.6297e-05, -7.6238e-05, -7.6227e-05, -7.6332e-05, -7.6319e-05,\n",
       "         -7.6335e-05, -7.6277e-05, -7.6306e-05, -7.6304e-05, -7.6320e-05],\n",
       "        [-7.4505e-05, -7.4350e-05, -7.4345e-05, -7.4593e-05, -7.4570e-05,\n",
       "         -7.4602e-05, -7.4483e-05, -7.4530e-05, -7.4543e-05, -7.4568e-05],\n",
       "        [-7.6042e-05, -7.6041e-05, -7.6041e-05, -7.6044e-05, -7.6044e-05,\n",
       "         -7.6046e-05, -7.6043e-05, -7.6043e-05, -7.6044e-05, -7.6044e-05],\n",
       "        [-7.4530e-05, -7.4428e-05, -7.4423e-05, -7.4598e-05, -7.4581e-05,\n",
       "         -7.4606e-05, -7.4518e-05, -7.4550e-05, -7.4561e-05, -7.4575e-05],\n",
       "        [-7.4771e-05, -7.4347e-05, -7.4345e-05, -7.5004e-05, -7.4960e-05,\n",
       "         -7.5003e-05, -7.4730e-05, -7.4850e-05, -7.4886e-05, -7.4943e-05],\n",
       "        [-7.6215e-05, -7.6045e-05, -7.6036e-05, -7.6314e-05, -7.6293e-05,\n",
       "         -7.6329e-05, -7.6194e-05, -7.6305e-05, -7.6259e-05, -7.6286e-05],\n",
       "        [-7.6219e-05, -7.6217e-05, -7.6276e-05, -7.6281e-05, -7.6280e-05,\n",
       "         -7.6222e-05, -7.6219e-05, -7.6280e-05, -7.6281e-05, -7.6280e-05],\n",
       "        [-7.7220e-05, -7.7127e-05, -7.7123e-05, -7.7278e-05, -7.7269e-05,\n",
       "         -7.7288e-05, -7.7201e-05, -7.7235e-05, -7.7246e-05, -7.7263e-05],\n",
       "        [-4.5695e-05,  3.6200e-05, -8.3428e-05, -6.9721e-05, -6.4345e-05,\n",
       "         -7.3384e-05, -4.8596e-06, -5.1189e-05, -5.5648e-05, -6.1638e-05],\n",
       "        [-7.0648e-05, -6.4281e-05, -6.4187e-05, -7.3893e-05, -7.3191e-05,\n",
       "         -7.4299e-05, -7.0239e-05, -7.1725e-05, -7.2225e-05, -7.2805e-05],\n",
       "        [-6.0624e-05,  8.0652e-05, -1.6077e-05, -7.2311e-05, -6.9933e-05,\n",
       "         -7.3588e-05, -5.8696e-05, -6.4186e-05, -6.5783e-05, -6.8594e-05],\n",
       "        [-7.3075e-05, -6.9933e-05, -6.9886e-05, -7.4439e-05, -7.4133e-05,\n",
       "         -7.4491e-05, -7.2895e-05, -7.3474e-05, -7.3685e-05, -7.4039e-05],\n",
       "        [-5.6182e-05, -7.5412e-05, -7.3261e-05, -7.1301e-05, -6.8110e-05,\n",
       "         -7.3336e-05, -5.3493e-05, -6.1417e-05, -6.3615e-05, -6.6579e-05],\n",
       "        [-7.4579e-05, -7.4526e-05, -7.4526e-05, -7.4603e-05, -7.4598e-05,\n",
       "         -7.4605e-05, -7.4575e-05, -7.4585e-05, -7.4588e-05, -7.4596e-05],\n",
       "        [-6.6909e-05, -5.2495e-05, -5.2199e-05, -7.3323e-05, -7.1910e-05,\n",
       "         -7.4046e-05, -6.5949e-05, -6.8935e-05, -6.9913e-05, -7.1194e-05],\n",
       "        [ 7.9175e-05,  4.6910e-04,  4.8905e-04, -8.8039e-05, -7.9523e-05,\n",
       "         -9.4380e-05, -2.1928e-05,  8.3312e-05,  3.1008e-05, -7.3767e-05],\n",
       "        [-5.7373e-05,  1.3426e-04,  3.5509e-05, -7.1572e-05, -6.8779e-05,\n",
       "         -7.3480e-05, -5.5041e-05, -6.1599e-05, -6.4370e-05, -6.7243e-05],\n",
       "        [-7.4106e-05, -7.3221e-05, -7.3198e-05, -7.4621e-05, -7.4493e-05,\n",
       "         -7.4624e-05, -7.4038e-05, -7.4254e-05, -7.4344e-05, -7.4462e-05],\n",
       "        [-5.6026e-05,  3.5976e-05,  8.0417e-05, -7.3020e-05, -7.0208e-05,\n",
       "         -7.4984e-05, -5.2832e-05, -6.2710e-05, -6.5551e-05, -6.8325e-05],\n",
       "        [-6.4513e-05, -1.4780e-05,  7.7650e-05, -7.4086e-05, -7.2340e-05,\n",
       "         -7.5378e-05, -6.2879e-05, -6.7271e-05, -6.9004e-05, -7.1194e-05],\n",
       "        [-5.8717e-05,  8.9441e-05,  8.6149e-05, -7.3203e-05, -7.0320e-05,\n",
       "         -7.6257e-05, -5.5464e-05, -6.3410e-05, -6.6123e-05, -6.8791e-05],\n",
       "        [-2.0038e-05,  3.6167e-04,  2.2208e-04, -6.2376e-05, -4.9794e-05,\n",
       "         -6.9276e-05,  7.2444e-06, -5.3029e-06, -2.2595e-05, -4.1657e-05],\n",
       "        [-7.2908e-05, -6.9833e-05, -6.9796e-05, -7.4376e-05, -7.4047e-05,\n",
       "         -7.4462e-05, -7.2705e-05, -7.3325e-05, -7.3592e-05, -7.3910e-05],\n",
       "        [-5.8445e-05,  9.2325e-05,  6.7652e-05, -7.2137e-05, -6.9511e-05,\n",
       "         -7.3474e-05, -5.6227e-05, -6.3012e-05, -6.5275e-05, -6.7858e-05],\n",
       "        [-7.4528e-05, -7.4391e-05, -7.4386e-05, -7.4599e-05, -7.4586e-05,\n",
       "         -7.4608e-05, -7.4517e-05, -7.4549e-05, -7.4558e-05, -7.4577e-05],\n",
       "        [-4.3646e-05, -2.3319e-05, -5.2036e-05, -7.0960e-05, -6.5739e-05,\n",
       "         -7.3979e-05, -3.9781e-05, -5.2578e-05, -5.6862e-05, -6.2225e-05],\n",
       "        [-7.0042e-05, -6.4763e-05, -6.7370e-05, -7.3989e-05, -7.3112e-05,\n",
       "         -7.4245e-05, -6.9522e-05, -7.1187e-05, -7.1856e-05, -7.2763e-05],\n",
       "        [-7.1958e-05, -6.5206e-05, -6.5124e-05, -7.4755e-05, -7.4147e-05,\n",
       "         -7.4928e-05, -7.1577e-05, -7.2787e-05, -7.3265e-05, -7.3887e-05],\n",
       "        [-7.4624e-05, -7.4519e-05, -7.4516e-05, -7.4662e-05, -7.4653e-05,\n",
       "         -7.4667e-05, -7.4612e-05, -7.4635e-05, -7.4640e-05, -7.4656e-05],\n",
       "        [-7.4462e-05, -7.2405e-05, -7.2379e-05, -7.5494e-05, -7.5250e-05,\n",
       "         -7.5534e-05, -7.4322e-05, -7.4753e-05, -7.4913e-05, -7.5176e-05],\n",
       "        [-1.4394e-05,  1.2285e-04,  1.4010e-04, -7.0834e-05, -6.2286e-05,\n",
       "         -7.5936e-05,  9.8922e-05,  6.8665e-05, -4.7722e-05, -5.7414e-05],\n",
       "        [-7.5192e-05, -7.3071e-05, -7.3018e-05, -7.6215e-05, -7.6000e-05,\n",
       "         -7.6315e-05, -7.4995e-05, -7.5461e-05, -7.5630e-05, -7.5902e-05],\n",
       "        [-5.0471e-05, -2.8627e-05, -8.5789e-05, -7.3401e-05, -6.8899e-05,\n",
       "         -7.5948e-05, -4.7529e-05, -5.8466e-05, -6.1989e-05, -6.6229e-05],\n",
       "        [ 8.0708e-05,  6.4117e-05, -8.4574e-05, -7.1775e-05, -6.7497e-05,\n",
       "         -7.5040e-05, -5.6825e-05, -5.5932e-05, -5.9818e-05, -6.5274e-05],\n",
       "        [-6.8928e-05,  7.2756e-05,  6.9010e-05, -7.5755e-05, -7.4382e-05,\n",
       "         -7.7008e-05, -6.7748e-05, -7.0990e-05, -7.2340e-05, -7.3588e-05],\n",
       "        [ 1.5097e-05, -2.3402e-05, -3.1601e-05, -7.7210e-05, -6.3031e-05,\n",
       "         -8.4237e-05, -6.5391e-05, -7.6835e-05, -1.1515e-05, -5.2392e-05]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.XI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../model/'\n",
    "t = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Caricato il checkpoint all'epoca:{t} \")\n",
    "model = Autoencoder(2601,2).to(device)\n",
    "optimizer = model.configure_optimizers()\n",
    "\n",
    "f1 = path + 'model' + '_' + str(t) + 'epochs' + '.pt'\n",
    "\n",
    "checkpoint = torch.load(f1)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_dict(loss_list)\n",
    "data.to_csv('./data'+'_'+str(t)+'epochs'+'.csv')\n",
    "for key in loss_list.keys():\n",
    "    plt.plot(loss_list[key],label = key)\n",
    "plt.plot(loss_val_list,label = 'validation')    \n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Loss con batch size di '+str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('./data'+'_'+str(t)+'epochs'+'.csv') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
