{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evH6sjsxsKWE"
   },
   "source": [
    "# A pendulum video and autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "trlxwPDloKs5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import sys\n",
    "syspath = 'SindyPendulum/'\n",
    "if syspath not in sys.path:\n",
    "    sys.path.append(syspath)\n",
    "    \n",
    "from sindy_library import SINDyLibrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qNbEXw0Uo3zR",
    "outputId": "7eabf512-f2cf-4429-bc0e-9af2374ed4cd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8VneYLUfl5bz"
   },
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pend(y, t,):\n",
    "    theta, omega = y\n",
    "    dydt = [omega, - np.sin(theta)]\n",
    "    return dydt\n",
    "\n",
    "def pend_damp(y, t,):\n",
    "    theta, omega = y\n",
    "    dydt = [omega, - np.sin(theta)-0.1*omega]\n",
    "    return dydt\n",
    "\n",
    "def select_ics(theta0,omegaics0):\n",
    "    ics = []\n",
    "    for i in range(n_ics):\n",
    "        for j in range(n_ics):\n",
    "            lim = (np.abs((omega0[j]**2)/2 - np.cos(theta0[i])))\n",
    "            if lim <  0.99 :\n",
    "                ics.append((theta0[i],omega0[j]))\n",
    "    return ics\n",
    "\n",
    "def wrap_to_pi(z):\n",
    "    z_mod = z % (2*np.pi)\n",
    "    subtract_m = (z_mod > np.pi) * (-2*np.pi)\n",
    "    return z_mod + subtract_m\n",
    "\n",
    "def image_gen(ics):\n",
    "    x = np.linspace(-1.5, 1.5, NX)\n",
    "    y = np.linspace(-1.5, 1.5, NY)\n",
    "    xx,yy = np.meshgrid(x, y)\n",
    "\n",
    "\n",
    "    data = np.empty([len(ics), len(t), len(x), len(y)],dtype = np.float32)\n",
    "    data2 = np.empty([len(ics), len(t), len(x), len(y)],dtype = np.float32)\n",
    "\n",
    "\n",
    "    for idx in range(len(ics)):\n",
    "        if(idx%100==0): print(idx,' su ', len(ics))\n",
    "        y0 = [ics[idx][0], ics[idx][1]]\n",
    "        sol = odeint(pend, y0,t)\n",
    "        theta = sol[:,0]\n",
    "        omega = sol[:,1]\n",
    "\n",
    "        temp = []\n",
    "        for i in range(len(theta)):\n",
    "            z = np.exp(- 20 *((xx - np.cos(theta[i] + np.pi/2))*(xx - \n",
    "                np.cos(theta[i] +np.pi/2))) - 20 * ((yy -np.sin(theta[i]+np.pi/2))*(yy -np.sin(theta[i]+np.pi/2))))\n",
    "            z = ((z - np.min(z))/(np.max(z)-np.min(z)))\n",
    "    \n",
    "            temp.append(z)\n",
    "        data[idx] = np.array(temp)\n",
    "        \n",
    "        temp = []\n",
    "        for i in range(len(omega)):            \n",
    "            exp = -20 * 2 * omega[i]*(np.cos(theta[i]+ np.pi/2) - np.sin(theta[i] + np.pi/2))\n",
    "            z = np.exp(- 20 *((xx - np.cos(theta[i] + np.pi/2))*(xx - \n",
    "                np.cos(theta[i] +np.pi/2))) - 20 * ((yy -np.sin(theta[i]+np.pi/2))*(yy -np.sin(theta[i]+np.pi/2))))\n",
    "            z = z * exp\n",
    "            z = ((z - np.min(z))/(np.max(z)-np.min(z)))\n",
    "            temp.append(z)\n",
    "        data2[idx] = np.array(temp)\n",
    "        \n",
    "    return data,data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  su  1432\n",
      "100  su  1432\n",
      "200  su  1432\n",
      "300  su  1432\n",
      "400  su  1432\n",
      "500  su  1432\n",
      "600  su  1432\n",
      "700  su  1432\n",
      "800  su  1432\n",
      "900  su  1432\n",
      "1000  su  1432\n",
      "1100  su  1432\n",
      "1200  su  1432\n",
      "1300  su  1432\n",
      "1400  su  1432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(143200, 2601)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ics = 50\n",
    "    \n",
    "#COSTANTI e PARAMETRI\n",
    "ta = 0.\n",
    "tb = 5\n",
    "dt = 0.05\n",
    "# tb = 10\n",
    "# dt = 0.1\n",
    "NX = 51\n",
    "NY = 51\n",
    "\n",
    "\n",
    "t = np.arange(ta, tb ,dt)\n",
    "theta0 = np.linspace(-np.pi,np.pi,n_ics)\n",
    "omega0 = np.linspace(-2.1, 2.1,n_ics)\n",
    "\n",
    "ics = select_ics(theta0,omega0)\n",
    "data,data2 = image_gen(ics)\n",
    "\n",
    "\n",
    "#questo reshape serve per mandare al autoencoder delle immagini flat\n",
    "#TODO verifica che sia corretto questo rehsape --> dovrebb essere ok fatto prova su colab\n",
    "X = data.reshape((len(ics) * len(t),NX * NY))\n",
    "Xdot = data2.reshape((len(ics) * len(t),NX * NY))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f31b3a7bf28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[123].reshape((51,51)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f31b38eb470>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Xdot[123].reshape((51,51)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdot[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UW2N4TZTbYsO",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([143200, 2601]), torch.Size([143200, 2601]), torch.float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.from_numpy(X).float().to(device)\n",
    "Xdot = torch.from_numpy(Xdot).float().to(device)\n",
    "X.shape, Xdot.shape, X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128880, 14320)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_size = round(X.shape[0] * 0.1)\n",
    "train_size = X.shape[0] - val_size\n",
    "train_size, val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "B2vYJ447_sxQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 8192\n",
    "my_dataset = TensorDataset(X,Xdot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_subset, val_subset = torch.utils.data.random_split(my_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_subset, shuffle=True, batch_size=batch_size)\n",
    "val_loader   = DataLoader(val_subset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lRG3Ea4CWWl"
   },
   "source": [
    "# Network\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "5ZSdKOTO8dFN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size,latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,32)\n",
    "        self.fc4 = nn.Linear(32,latent_dim)\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            print(m)\n",
    "            if isinstance(m, nn.Linear):\n",
    "                #nn.init.xavier_normal_(m.weight) #per la sigmoid\n",
    "                nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))   \n",
    "        x = torch.relu(self.fc4(x))\n",
    "        return x \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size,latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim,32)\n",
    "        self.fc2 = nn.Linear(32,64)\n",
    "        self.fc3 = nn.Linear(64,128)\n",
    "        self.fc4 = nn.Linear(128,input_size)\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))   \n",
    "        x = torch.relu(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                #nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(input_size,latent_dim)\n",
    "        self.decoder = Decoder(input_size,latent_dim)\n",
    "        self.SINDyLibrary = SINDyLibrary(\n",
    "            device=device,\n",
    "            latent_dim=latent_dim,\n",
    "            include_biases=False,\n",
    "            include_states=True,\n",
    "            include_sin=True,\n",
    "            include_cos=False,\n",
    "            include_multiply_pairs=False, #non ho capito cosa é ma conta due volte le coppie  \n",
    "            poly_order=1,\n",
    "            include_sqrt=False,\n",
    "            include_inverse=False,\n",
    "            include_sign_sqrt_of_diff=False)\n",
    "        \n",
    "\n",
    "        self.XI = nn.Parameter(torch.full((self.SINDyLibrary.number_candidate_functions,latent_dim),1.,dtype = torch.float32,requires_grad=True,device = device))\n",
    "#        self.XI = nn.Parameter(torch.randn((self.SINDyLibrary.number_candidate_functions,latent_dim),\n",
    "        self.XI_coefficient_mask = torch.ones((self.SINDyLibrary.number_candidate_functions,latent_dim),dtype = torch.float32, device=device)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        learning_rate = 1e-4\n",
    "        return torch.optim.SGD(self.parameters(), lr=learning_rate, momentum = 0.9)\n",
    "        #return torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "    def t_derivative(self,input, xdot, weights, biases, activation='sigmoid'):\n",
    "        \"\"\"\n",
    "        Compute the first order time derivatives by propagating through the network.\n",
    "        da[l]dt = xdot * da[l]dx = xdot * product(g'(w[l]a[l-1] + b[l])* w[l])\n",
    "        Arguments:\n",
    "            input - 2D tensorflow array, input to the network. Dimensions are number of time points\n",
    "            by number of state variables.\n",
    "            xdot - First order time derivatives of the input to the network. quello che conosciamo\n",
    "            weights - List of tensorflow arrays containing the network weights\n",
    "            biases - List of tensorflow arrays containing the network biases\n",
    "            activation - String specifying which activation function to use. Options are\n",
    "            'elu' (exponential linear unit), 'relu' (rectified linear unit), 'sigmoid',\n",
    "            or linear.\n",
    "\n",
    "        Returns:\n",
    "            dadt - Tensorflow array, first order time derivatives of the network output.\n",
    "        \"\"\"\n",
    "        a   = input\n",
    "        dadt = xdot #per le condizioni iniziali\n",
    "\n",
    "        if activation == 'sigmoid':\n",
    "            for i in range(len(weights) - 1):\n",
    "                z = torch.matmul(a, weights[i].T) + biases[i]\n",
    "                a = torch.sigmoid(z)\n",
    "                gprime = a * (1-a)\n",
    "                dadt = gprime * torch.matmul(dadt, weights[i].T)\n",
    "            dadt = torch.matmul(dadt, weights[-1].T) #fuori dal ciclo bisogna ancora moltiplicare per i pesi dell ultimo livello\n",
    "            \n",
    "        elif activation == 'relu':\n",
    "            for i in range(len(weights) - 1):\n",
    "                z = torch.matmul(a, weights[i].T) + biases[i]\n",
    "                a = torch.relu(z)\n",
    "                dadt = (z > 0).float() * torch.matmul(dadt, weights[i].T)    \n",
    "            dadt = torch.matmul(dadt, weights[-1].T) #fuori dal ciclo bisogna ancora moltiplicare per i pesi dell ultimo livello\n",
    "        return dadt #nel caso che ci serve dadt sará l output dell encoder ossia le latent variables!\n",
    "\n",
    "    \n",
    "    \n",
    "    def compute_quantities(self,x,xdot):\n",
    "    \n",
    "        z = self.encoder(x)\n",
    "        xtilde = self.decoder(z)\n",
    "\n",
    "        theta = self.SINDyLibrary.transform(z) \n",
    "        zdot_hat = torch.matmul(theta, self.XI_coefficient_mask * self.XI)\n",
    "        \n",
    "        encoder_parameters = list(self.encoder.parameters())\n",
    "        encoder_weight_list = [w for w in encoder_parameters if len(w.shape) == 2]\n",
    "        encoder_biases_list = [b for b in encoder_parameters if len(b.shape) == 1]\n",
    "        zdot = self.t_derivative(x, xdot, encoder_weight_list, encoder_biases_list, activation='relu')                                               \n",
    "\n",
    "        #print(\"propagazione sul decoder\")\n",
    "        decoder_parameters = list(self.decoder.parameters())\n",
    "        decoder_weight_list = [w for w in decoder_parameters if len(w.shape) == 2]\n",
    "        decoder_biases_list = [b for b in decoder_parameters if len(b.shape) == 1]\n",
    "        xtildedot = self.t_derivative(z, zdot_hat, decoder_weight_list, decoder_biases_list, activation='relu')    \n",
    "        \n",
    "        return xtilde, xtildedot, z, zdot, zdot_hat\n",
    "\n",
    "    def loss_function(self, x, xdot, xtilde, xtildedot, zdot, zdot_hat,XI):\n",
    "        mse = nn.MSELoss()\n",
    "        alpha1 = 5e-4\n",
    "        alpha2 = 5e-5\n",
    "        alpha3 = 1e-5\n",
    "\n",
    "\n",
    "        loss = {}\n",
    "        loss['recon_loss'] = mse(x, xtilde) #errore di ricostruzione \n",
    "        loss ['sindy_loss_x'] = mse(xdot, xtildedot) \n",
    "        loss ['sindy_loss_z'] = mse(zdot, zdot_hat) \n",
    "        loss['sindy_regular_loss'] = torch.sum(torch.abs(XI)) #norma L1 degli XI\n",
    "        loss['tot'] = loss['recon_loss'] + alpha1*loss['sindy_loss_x'] + alpha2*loss['sindy_loss_z'] + alpha3*loss['sindy_regular_loss']\n",
    "        tot = loss['tot']\n",
    "        return tot, loss\n",
    "    \n",
    "    def forward(self, x, xdot):\n",
    "        return self.compute_quantities(x, xdot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "c4mBzZuzxPYP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_size = X.shape[1]\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "sOuh7zJeoRmH",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (fc1): Linear(in_features=2601, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=100, bias=True)\n",
      ")\n",
      "Linear(in_features=2601, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=100, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(input_size,latent_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "8r_OGkXz2Mgl",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.SINDyLibrary.number_candidate_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.SINDyLibrary.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZqwZy2XmMum"
   },
   "source": [
    "# Parameters and Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "zrBLCBxXTPaa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sequential_threshold(t):\n",
    "    if (t % seq_thres == 0 and t>1):\n",
    "        model.XI_coefficient_mask = torch.abs(model.XI) > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(t):\n",
    "    if SAVE == True:\n",
    "        if t % saving_rate == 0 and t > 0:\n",
    "            print('salvataggio a ',t,\"epoche\")\n",
    "            f1 = path + 'model' + '_' + str(t) + 'epochs' + '.pt'\n",
    "            torch.save({\n",
    "            'epoch': t,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': model.configure_optimizers().state_dict(),\n",
    "            'loss': model.loss_function,\n",
    "            'sindy_coefficients': model.XI,\n",
    "            'coefficient_mask' : model.XI_coefficient_mask\n",
    "            }, f1)\n",
    "            \n",
    "            XI = model.XI.cpu().detach().numpy()\n",
    "            np.save(path + 'model' + '_' + str(t) + 'epochs' + '.npy',XI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_model(t):\n",
    "    f = open(path + 'model_equation' + '_' + str(t) + '.txt', 'w')\n",
    "    coefficient_mask = model.XI_coefficient_mask.cpu().detach().numpy()\n",
    "    XI = model.XI.cpu().detach().numpy()\n",
    "    feature_list = model.SINDyLibrary.get_feature_names()\n",
    "    for j in range(latent_dim):\n",
    "        for i in range(len(feature_list)-1):\n",
    "            coeff = XI[i][j] * coefficient_mask[i][j]\n",
    "            if  abs(coeff) >= 0.1 and coeff != 0:\n",
    "                #print(f\"dz{j} = {coeff:.4f} {feature_list[i]}\")\n",
    "                f.write(f\"dz{j} = {coeff:.6f} {feature_list[i]}\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training step for one epoch\n",
    "def train_step(loss_list):\n",
    "        \n",
    "    #queste serve per le loss di ogni batch\n",
    "    loss_epoch = {}\n",
    "    loss_epoch['recon_loss'] = []\n",
    "    loss_epoch['sindy_loss_x'] = []\n",
    "    loss_epoch['sindy_loss_z'] = []\n",
    "    loss_epoch['sindy_regular_loss'] = []\n",
    "    loss_epoch['tot'] = []\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (X,Xdot) in enumerate (train_loader):\n",
    "        X.to(device) #per passarlo alla gpu\n",
    "        Xdot.to(device)\n",
    "        #forward pass \n",
    "        xtilde, xtildedot, z, zdot, zdot_hat = model(X,Xdot)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer = model.configure_optimizers()\n",
    "        loss, loss_dict = model.loss_function(X, Xdot, xtilde, xtildedot, zdot, zdot_hat,model.XI)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for key in loss_epoch.keys():\n",
    "            loss_epoch[key].append(loss_dict[key].item())\n",
    "        \n",
    "        \n",
    "    for key in loss_epoch.keys():\n",
    "            loss_list[key].append(sum(loss_epoch[key])/len(loss_epoch[key]))\n",
    "            \n",
    "    del loss_epoch,loss_dict,xtilde, xtildedot, z, zdot, zdot_hat,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(loss_val_list):\n",
    "    loss_val_epoch = []\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "    for batch, (X,Xdot) in enumerate (val_loader):\n",
    "        X.to(device) #per passarlo alla gpu\n",
    "        Xdot.to(device)\n",
    "        #forward pass \n",
    "        xtilde, xtildedot, z, zdot, zdot_hat = model(X,Xdot)\n",
    "        # validation loss \n",
    "        loss, _ = model.loss_function(X, Xdot, xtilde, xtildedot, zdot, zdot_hat,model.XI)\n",
    "        loss_val_epoch.append(loss.item())\n",
    "        del  xtilde, xtildedot, z, zdot, zdot_hat,loss\n",
    "\n",
    "    loss_val_list.append(sum(loss_val_epoch)/len(loss_val_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_loss(t):\n",
    "    if t % loss_rate == 0:\n",
    "        print()\n",
    "        print(f\"Epoch {t}\\n-------------------------------\")\n",
    "        for key in loss_list.keys():\n",
    "            temp = loss_list[key]\n",
    "            print(f'{key} of epoch {t}: {temp[-1]:.3e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION = False\n",
    "SAVE = True\n",
    "\n",
    "epochs = 2000\n",
    "path = '../model/'\n",
    "\n",
    "seq_thres = 100   # numero epoche ogni quanto fare seq thres\n",
    "\n",
    "equation_rate = 100 #print delle equazioni trovate\n",
    "\n",
    "saving_rate = 100 # numero epoche in cui salvo il modello e gli XI\n",
    "\n",
    "loss_rate = 50  #print delle loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 191\n",
      "epoch: 192\n",
      "epoch: 193\n",
      "epoch: 194\n",
      "epoch: 195\n",
      "epoch: 196\n",
      "epoch: 197\n",
      "epoch: 198\n",
      "epoch: 199\n",
      "epoch: 200\n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "recon_loss of epoch 200: 1.947e-03\n",
      "sindy_loss_x of epoch 200: 2.772e-01\n",
      "sindy_loss_z of epoch 200: 1.458e-01\n",
      "sindy_regular_loss of epoch 200: 1.364e+04\n",
      "tot of epoch 200: 1.385e-01\n",
      "salvataggio a  200 epoche\n",
      "epoch: 201\n",
      "epoch: 202\n",
      "epoch: 203\n",
      "epoch: 204\n",
      "epoch: 205\n",
      "epoch: 206\n",
      "epoch: 207\n",
      "epoch: 208\n",
      "epoch: 209\n",
      "epoch: 210\n",
      "epoch: 211\n",
      "epoch: 212\n",
      "epoch: 213\n",
      "epoch: 214\n",
      "epoch: 215\n",
      "epoch: 216\n",
      "epoch: 217\n",
      "epoch: 218\n",
      "epoch: 219\n",
      "epoch: 220\n",
      "epoch: 221\n",
      "epoch: 222\n",
      "epoch: 223\n",
      "epoch: 224\n",
      "epoch: 225\n",
      "epoch: 226\n",
      "epoch: 227\n",
      "epoch: 228\n",
      "epoch: 229\n",
      "epoch: 230\n",
      "epoch: 231\n",
      "epoch: 232\n",
      "epoch: 233\n",
      "epoch: 234\n",
      "epoch: 235\n",
      "epoch: 236\n",
      "epoch: 237\n",
      "epoch: 238\n",
      "epoch: 239\n",
      "epoch: 240\n",
      "epoch: 241\n",
      "epoch: 242\n",
      "epoch: 243\n",
      "epoch: 244\n",
      "epoch: 245\n",
      "epoch: 246\n"
     ]
    }
   ],
   "source": [
    "loss_list = {}\n",
    "loss_list['recon_loss'] = []\n",
    "loss_list['sindy_loss_x'] = []\n",
    "loss_list['sindy_loss_z'] = []\n",
    "loss_list['sindy_regular_loss'] = []\n",
    "loss_list['tot'] = []\n",
    "loss_val_list = []\n",
    "\n",
    "\n",
    "while t <= epochs:\n",
    "    print(\"epoch:\",t)\n",
    "    train_step(loss_list)\n",
    "    \n",
    "    validation_step(loss_val_list)\n",
    "    \n",
    "    print_loss(t)\n",
    "\n",
    "    save_model(t)\n",
    "    \n",
    "    sequential_threshold(t)\n",
    "    \n",
    "    if t % equation_rate == 0 and t>1:\n",
    "        print_model(t)\n",
    "        data = pd.DataFrame.from_dict(loss_list)\n",
    "        data.to_csv(path + 'data_'+str(t)+'epochs'+'.csv')\n",
    "    t = t + 1\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(loss_list['tot'])\n",
    "#plt.plot(loss_list['sindy_loss_z'])\n",
    "plt.plot(loss_list['sindy_loss_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../model_1e5/' # con regolarizzatore a 1e-3 non avrá senso spero\n",
    "#path = '../model_zero/' #con regolarizzatore a zero\n",
    "#path = '../model_alphae6/'  # con regolarizzatore a 1e-6\n",
    "t = 1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricato il checkpoint all'epoca:1600 \n",
      "Encoder(\n",
      "  (fc1): Linear(in_features=2601, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Linear(in_features=2601, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Caricato il checkpoint all'epoca:{t} \")\n",
    "model = Autoencoder(2601,10).to(device)\n",
    "optimizer = model.configure_optimizers()\n",
    "\n",
    "f1 = path + 'model' + '_' + str(t) + 'epochs' + '.pt'\n",
    "\n",
    "checkpoint = torch.load(f1)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_dict(loss_list)\n",
    "data.to_csv('./data'+'_'+str(t)+'epochs'+'.csv')\n",
    "for key in loss_list.keys():\n",
    "    plt.plot(loss_list[key],label = key)\n",
    "plt.plot(loss_val_list,label = 'validation')    \n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Loss con batch size di '+str(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('./data'+'_'+str(t)+'epochs'+'.csv') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
