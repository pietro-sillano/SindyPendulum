{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TO DO LIST\n\n11. capire come fare una prediction con quanto ottenuto\n15. aggiungere un early stopping\n","metadata":{"id":"evH6sjsxsKWE"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n#from google.colab import files\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport numpy as np\nimport sys\nsyspath = 'SindyPendulum/'\nif syspath not in sys.path:\n    sys.path.append(syspath)\nimport time","metadata":{"id":"trlxwPDloKs5","execution":{"iopub.status.busy":"2021-12-21T16:58:54.445801Z","iopub.execute_input":"2021-12-21T16:58:54.446386Z","iopub.status.idle":"2021-12-21T16:58:55.892928Z","shell.execute_reply.started":"2021-12-21T16:58:54.446295Z","shell.execute_reply":"2021-12-21T16:58:55.892208Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Get cpu or gpu device for training.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using {} device\".format(device))","metadata":{"id":"qNbEXw0Uo3zR","outputId":"7eabf512-f2cf-4429-bc0e-9af2374ed4cd","execution":{"iopub.status.busy":"2021-12-21T16:58:59.092288Z","iopub.execute_input":"2021-12-21T16:58:59.092780Z","iopub.status.idle":"2021-12-21T16:58:59.139372Z","shell.execute_reply.started":"2021-12-21T16:58:59.092741Z","shell.execute_reply":"2021-12-21T16:58:59.138563Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data Generation","metadata":{"id":"8VneYLUfl5bz"}},{"cell_type":"code","source":"!git clone https://github.com/pietro-sillano/SindyPendulum.git","metadata":{"id":"ojotcMcmDoRF","outputId":"f8784ec7-cc45-4978-9da9-c63afc4a8be0","execution":{"iopub.status.busy":"2021-12-21T16:59:01.502759Z","iopub.execute_input":"2021-12-21T16:59:01.503044Z","iopub.status.idle":"2021-12-21T16:59:06.031316Z","shell.execute_reply.started":"2021-12-21T16:59:01.502998Z","shell.execute_reply":"2021-12-21T16:59:06.030415Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!cd SindyPendulum && git pull","metadata":{"id":"jiqk7akK2aoa","outputId":"fc81c54e-7390-4c2c-92f9-8d69fe224a7f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"afRdAZnLIC-O"}},{"cell_type":"code","source":"from sindy_library import SINDyLibrary","metadata":{"id":"wwWPtC6xKbKb","execution":{"iopub.status.busy":"2021-12-21T16:59:06.033466Z","iopub.execute_input":"2021-12-21T16:59:06.033750Z","iopub.status.idle":"2021-12-21T16:59:06.042079Z","shell.execute_reply.started":"2021-12-21T16:59:06.033713Z","shell.execute_reply":"2021-12-21T16:59:06.041426Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sindy_library_numpy import SINDyNumpy","metadata":{"id":"q-eylOGYs7oC","execution":{"iopub.status.busy":"2021-12-21T16:59:06.367659Z","iopub.execute_input":"2021-12-21T16:59:06.368018Z","iopub.status.idle":"2021-12-21T16:59:06.374871Z","shell.execute_reply.started":"2021-12-21T16:59:06.367985Z","shell.execute_reply":"2021-12-21T16:59:06.374103Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#!python SindyPendulum/lorentz.py  -i 1000","metadata":{"id":"JwRkfRiGKbKc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python SindyPendulum/data_pendulum_image.py  -i 26","metadata":{"id":"d1DKMT2rsJPt","outputId":"572f26bd-2cd1-47e4-8ebf-c37d6add998a","execution":{"iopub.status.busy":"2021-12-21T17:00:10.244187Z","iopub.execute_input":"2021-12-21T17:00:10.244463Z","iopub.status.idle":"2021-12-21T17:00:21.342667Z","shell.execute_reply.started":"2021-12-21T17:00:10.244430Z","shell.execute_reply":"2021-12-21T17:00:21.341838Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/gdrive')","metadata":{"id":"tF0zoK0y3wVI","outputId":"f9293d9e-2a01-4268-b9cf-ae96c0e90d4c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /content/gdrive/My Drive/","metadata":{"id":"kPEvHiG431LS","outputId":"4fb625d5-f440-4fd6-9e2d-e19663b6ebe0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv X.npy /content/gdrive/MyDrive/","metadata":{"id":"KEpv96Sc375A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv Xdot.npy /content/gdrive/MyDrive/","metadata":{"id":"kQn8CKn84jte"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.load('/content/gdrive/MyDrive/X.npy')\nXdot = np.load('/content/gdrive/MyDrive/Xdot.npy')","metadata":{"id":"GUIqs9cQNktG","outputId":"d695a2f3-f5b9-4527-ec29-7fbd48e76827"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.load('./X.npy')\nXdot = np.load('./Xdot.npy')","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:00:25.754420Z","iopub.execute_input":"2021-12-21T17:00:25.755291Z","iopub.status.idle":"2021-12-21T17:00:26.007548Z","shell.execute_reply.started":"2021-12-21T17:00:25.755235Z","shell.execute_reply":"2021-12-21T17:00:26.006763Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"id":"57E3E3Cqb2Mf","outputId":"92173807-0d3a-4e60-fb74-57d51fc37a83","execution":{"iopub.status.busy":"2021-12-21T17:00:26.009270Z","iopub.execute_input":"2021-12-21T17:00:26.009540Z","iopub.status.idle":"2021-12-21T17:00:26.014687Z","shell.execute_reply.started":"2021-12-21T17:00:26.009506Z","shell.execute_reply":"2021-12-21T17:00:26.014045Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"X = torch.from_numpy(X).float().to(device)\nXdot = torch.from_numpy(Xdot).float().to(device)\nX.shape, Xdot.shape, X.dtype","metadata":{"id":"UW2N4TZTbYsO","execution":{"iopub.status.busy":"2021-12-21T17:00:26.432542Z","iopub.execute_input":"2021-12-21T17:00:26.433242Z","iopub.status.idle":"2021-12-21T17:00:26.612511Z","shell.execute_reply.started":"2021-12-21T17:00:26.433202Z","shell.execute_reply":"2021-12-21T17:00:26.611816Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"val_size = round(X.shape[0] * 0.1)\ntrain_size = X.shape[0] - val_size\ntrain_size, val_size","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:00:27.189483Z","iopub.execute_input":"2021-12-21T17:00:27.189744Z","iopub.status.idle":"2021-12-21T17:00:27.195470Z","shell.execute_reply.started":"2021-12-21T17:00:27.189714Z","shell.execute_reply":"2021-12-21T17:00:27.194812Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"batch_size = 1024\nmy_dataset = TensorDataset(X,Xdot)\n#dataloader = DataLoader(my_dataset,batch_size=batch_size, shuffle=True)","metadata":{"id":"B2vYJ447_sxQ","execution":{"iopub.status.busy":"2021-12-21T17:00:27.414122Z","iopub.execute_input":"2021-12-21T17:00:27.414542Z","iopub.status.idle":"2021-12-21T17:00:27.422236Z","shell.execute_reply.started":"2021-12-21T17:00:27.414498Z","shell.execute_reply":"2021-12-21T17:00:27.421339Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_subset, val_subset = torch.utils.data.random_split(my_dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_subset, shuffle=True, batch_size=batch_size)\nval_loader   = DataLoader(val_subset, shuffle=False, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:00:29.791938Z","iopub.execute_input":"2021-12-21T17:00:29.792214Z","iopub.status.idle":"2021-12-21T17:00:29.801929Z","shell.execute_reply.started":"2021-12-21T17:00:29.792183Z","shell.execute_reply":"2021-12-21T17:00:29.801065Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Network\n\n\n","metadata":{"id":"9lRG3Ea4CWWl"}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_size,latent_dim):\n        super(Encoder, self).__init__()\n        self.fc1 = nn.Linear(input_size,512)\n        self.fc2 = nn.Linear(512,128)\n        self.fc3 = nn.Linear(128,64)\n        self.fc4 = nn.Linear(64,latent_dim)\n        self.initialize_weights()\n\n    def initialize_weights(self):\n        for m in self.modules():\n            print(m)\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        #x = torch.sigmoid(self.fc1(x))\n        \n        #x = torch.sigmoid(self.fc2(x))\n        #x = torch.sigmoid(self.fc3(x))   \n        #x = torch.sigmoid(self.fc4(x))\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = torch.relu(self.fc3(x))   \n        x = torch.relu(self.fc4(x))\n        return x \n\nclass Decoder(nn.Module):\n    def __init__(self, input_size,latent_dim):\n        super(Decoder, self).__init__()\n        self.fc1 = nn.Linear(latent_dim,64)\n        self.fc2 = nn.Linear(64,128)\n        self.fc3 = nn.Linear(128,512)\n        self.fc4 = nn.Linear(512,input_size)\n        self.initialize_weights()\n\n    def forward(self, x):\n        #x = torch.sigmoid(self.fc1(x))\n        #x = torch.sigmoid(self.fc2(x))\n        #x = torch.sigmoid(self.fc3(x))   \n        #x = torch.sigmoid(self.fc4(x))\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = torch.relu(self.fc3(x))   \n        x = torch.relu(self.fc4(x))\n        return x\n\n    def initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n\nclass Autoencoder(nn.Module):\n    def __init__(self, input_size, latent_dim):\n        super(Autoencoder, self).__init__()\n        self.encoder = Encoder(input_size,latent_dim)\n        self.decoder = Decoder(input_size,latent_dim)\n        self.SINDyLibrary = SINDyLibrary(\n            device=device,\n            latent_dim=latent_dim,\n            include_biases=False,\n            include_states=True,\n            include_sin=True,\n            include_cos=True,\n            include_multiply_pairs=True,\n            poly_order=1,\n            include_sqrt=True,\n            include_inverse=False,\n            include_sign_sqrt_of_diff=False)\n        \n#        self.XI = nn.Parameter(torch.full((self.SINDyLibrary.number_candidate_functions,latent_dim), 0.1,dtype = torch.float32,requires_grad=True,device = device))\n#        self.XI = nn.Parameter(torch.full((self.SINDyLibrary.number_candidate_functions,latent_dim),1.,dtype = torch.float32,device = device))\n        self.XI = nn.Parameter(torch.full((self.SINDyLibrary.number_candidate_functions,latent_dim),1.,dtype = torch.float32,requires_grad=True,device = device))\n\n        self.XI_coefficient_mask = torch.ones((self.SINDyLibrary.number_candidate_functions,latent_dim),dtype = torch.float32, device=device)\n\n    def configure_optimizers(self):\n        learning_rate = 1e-4\n#        return torch.optim.SGD(self.parameters(), lr=learning_rate)\n        return torch.optim.Adam(self.parameters(), lr=learning_rate)\n\n\n    def t_derivative(self,input, xdot, weights, biases, activation='sigmoid'):\n        \"\"\"\n        Compute the first order time derivatives by propagating through the network.\n        da[l]dt = xdot * da[l]dx = xdot * product(g'(w[l]a[l-1] + b[l])* w[l])\n        Arguments:\n            input - 2D tensorflow array, input to the network. Dimensions are number of time points\n            by number of state variables.\n            xdot - First order time derivatives of the input to the network. quello che conosciamo\n            weights - List of tensorflow arrays containing the network weights\n            biases - List of tensorflow arrays containing the network biases\n            activation - String specifying which activation function to use. Options are\n            'elu' (exponential linear unit), 'relu' (rectified linear unit), 'sigmoid',\n            or linear.\n\n        Returns:\n            dadt - Tensorflow array, first order time derivatives of the network output.\n        \"\"\"\n        a   = input\n        dadt = xdot #per le condizioni iniziali\n\n        if activation == 'sigmoid':\n            for i in range(len(weights) - 1):\n                z = torch.matmul(a, weights[i].T) + biases[i]\n                a = torch.sigmoid(z)\n                gprime = a * (1-a)\n                dadt = gprime * torch.matmul(dadt, weights[i].T)\n            dadt = torch.matmul(dadt, weights[-1].T) #fuori dal ciclo bisogna ancora moltiplicare per i pesi dell ultimo livello\n            \n        elif activation == 'relu':\n            for i in range(len(weights) - 1):\n                #print('modulo n ',i)\n                #print('weights',weights[i].shape)\n                z = torch.matmul(a, weights[i].T) + biases[i]\n                #print('z:',z.shape)\n                a = torch.relu(z)\n                #print('a:',a.shape)\n                dadt = (z > 0).float() * torch.matmul(dadt, weights[i].T)    \n            dadt = torch.matmul(dadt, weights[-1].T) #fuori dal ciclo bisogna ancora moltiplicare per i pesi dell ultimo livello\n            #print(dadt)\n        return dadt #nel caso che ci serve dadt sará l output dell encoder ossia le latent variables!\n\n    \n    \n    def compute_quantities(self,x,xdot):\n    \n        z = self.encoder(x)\n        xtilde = self.decoder(z)\n\n        theta = self.SINDyLibrary.transform(z) \n        zdot_hat = torch.matmul(theta, self.XI_coefficient_mask * self.XI)\n        \n        encoder_parameters = list(self.encoder.parameters())\n        encoder_weight_list = [w for w in encoder_parameters if len(w.shape) == 2]\n        encoder_biases_list = [b for b in encoder_parameters if len(b.shape) == 1]\n        zdot = self.t_derivative(x, xdot, encoder_weight_list, encoder_biases_list, activation='relu')                                               \n\n        #print(\"propagazione sul decoder\")\n        decoder_parameters = list(self.decoder.parameters())\n        decoder_weight_list = [w for w in decoder_parameters if len(w.shape) == 2]\n        decoder_biases_list = [b for b in decoder_parameters if len(b.shape) == 1]\n        xtildedot = self.t_derivative(z, zdot_hat, decoder_weight_list, decoder_biases_list, activation='relu')    \n        \n        if(DEBUG == True):\n            print('z',z)\n            print(' xtilde',xtilde)\n            print('theta',theta)\n            print('max theta',theta.max())\n            print('zdot',zdot)\n            print('zdothat',zdot_hat)\n            print('xtildedot',xtildedot)\n\n\n        return xtilde, xtildedot, z, zdot, zdot_hat\n\n    def loss_function(self, x, xdot, xtilde, xtildedot, zdot, zdot_hat,XI):\n        mse = nn.MSELoss()\n        alpha1 = 5e-4\n        alpha2 = 5e-5\n        alpha3 = 1e-5\n        loss = {}\n        loss['recon_loss'] = mse(x, xtilde) #errore di ricostruzione \n        loss ['sindy_loss_x'] = mse(xdot, xtildedot) \n        loss ['sindy_loss_z'] = mse(zdot, zdot_hat) \n        loss['sindy_regular_loss'] = torch.sum(torch.abs(XI)) #norma L1 degli XI\n        loss['tot'] = loss['recon_loss'] + alpha1*loss['sindy_loss_x'] + alpha2*loss['sindy_loss_z'] + alpha3*loss['sindy_regular_loss']\n        tot = loss['tot']\n        return tot, loss\n    \n    def forward(self, x, xdot):\n        return self.compute_quantities(x, xdot)","metadata":{"id":"5ZSdKOTO8dFN","execution":{"iopub.status.busy":"2021-12-21T17:00:32.284780Z","iopub.execute_input":"2021-12-21T17:00:32.285275Z","iopub.status.idle":"2021-12-21T17:00:32.322049Z","shell.execute_reply.started":"2021-12-21T17:00:32.285237Z","shell.execute_reply":"2021-12-21T17:00:32.321060Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"input_size = X.shape[1]\nlatent_dim = 10","metadata":{"id":"c4mBzZuzxPYP","execution":{"iopub.status.busy":"2021-12-21T17:00:32.743794Z","iopub.execute_input":"2021-12-21T17:00:32.744557Z","iopub.status.idle":"2021-12-21T17:00:32.748127Z","shell.execute_reply.started":"2021-12-21T17:00:32.744521Z","shell.execute_reply":"2021-12-21T17:00:32.747423Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = Autoencoder(input_size,latent_dim).to(device)","metadata":{"id":"sOuh7zJeoRmH","execution":{"iopub.status.busy":"2021-12-21T17:00:32.952486Z","iopub.execute_input":"2021-12-21T17:00:32.952960Z","iopub.status.idle":"2021-12-21T17:00:33.795333Z","shell.execute_reply.started":"2021-12-21T17:00:32.952928Z","shell.execute_reply":"2021-12-21T17:00:33.794474Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model.SINDyLibrary.number_candidate_functions","metadata":{"id":"8r_OGkXz2Mgl","execution":{"iopub.status.busy":"2021-12-21T17:00:33.797059Z","iopub.execute_input":"2021-12-21T17:00:33.797396Z","iopub.status.idle":"2021-12-21T17:00:34.635614Z","shell.execute_reply.started":"2021-12-21T17:00:33.797356Z","shell.execute_reply":"2021-12-21T17:00:34.634961Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Parameters and Training\n","metadata":{"id":"6ZqwZy2XmMum"}},{"cell_type":"code","source":"def sequential_threshold(t):\n    if (t % 500 == 0 and t>1):\n        model.XI_coefficient_mask = torch.abs(model.XI) > 0.01\n        print_model()","metadata":{"id":"zrBLCBxXTPaa","execution":{"iopub.status.busy":"2021-12-21T17:00:34.873844Z","iopub.execute_input":"2021-12-21T17:00:34.874100Z","iopub.status.idle":"2021-12-21T17:00:35.089795Z","shell.execute_reply.started":"2021-12-21T17:00:34.874070Z","shell.execute_reply":"2021-12-21T17:00:35.089011Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def print_model():\n    model.XI_coefficient_mask.cpu().detach().numpy()\n    XI = model.XI.cpu().detach().numpy()\n    for i in range(len(feature_list)-1):\n        for j in range(latent_dim-1):\n            coeff = XI[i][j] * coefficient_mask[i][j]\n            if  coeff !=0:\n                print(f\"z{j} = {coeff:.4f} {feature_list[i]}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:55:09.033562Z","iopub.execute_input":"2021-12-21T17:55:09.033826Z","iopub.status.idle":"2021-12-21T17:55:09.039732Z","shell.execute_reply.started":"2021-12-21T17:55:09.033790Z","shell.execute_reply":"2021-12-21T17:55:09.038918Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"epochs = 4000\nDEBUG = False\nVALIDATION = True\nSAVE = True\nSEQ_TRES = True\n\nloss_list = {}\nloss_list['recon_loss'] = []\nloss_list['sindy_loss_x'] = []\nloss_list['sindy_loss_z'] = []\nloss_list['sindy_regular_loss'] = []\n#loss_list['validation'] = []\nloss_list['tot'] = []\nloss_val_list = []\n\n\nfor t in range(epochs):\n    #start = time.time()\n    \n    #queste serve per le loss di ogni batch\n    loss_epoch = {}\n    loss_epoch['recon_loss'] = []\n    loss_epoch['sindy_loss_x'] = []\n    loss_epoch['sindy_loss_z'] = []\n    loss_epoch['sindy_regular_loss'] = []\n    #loss_epoch['validation'] = []\n    loss_epoch['tot'] = []\n    loss_val_epoch = []\n    \n    model.train()\n    for batch, (X,Xdot) in enumerate (train_loader):\n        X.to(device) #per passarlo alla gpu\n        Xdot.to(device)\n        #forward pass \n        xtilde, xtildedot, z, zdot, zdot_hat = model(X,Xdot)\n\n        # Backpropagation\n        optimizer = model.configure_optimizers()\n        loss, loss_dict = model.loss_function(X, Xdot, xtilde, xtildedot, zdot, zdot_hat,model.XI)\n        loss.backward()\n        del  xtilde, xtildedot, z, zdot, zdot_hat,loss\n        optimizer.step()\n        optimizer.zero_grad()\n\n        current = batch * len(X)\n\n        for key in loss_epoch.keys():\n            loss_epoch[key].append(loss_dict[key].item())\n        del loss_dict\n\n    for key in loss_epoch.keys():\n        loss_list[key].append(sum(loss_epoch[key])/len(loss_epoch[key]))\n    del loss_epoch\n    \n\n\n\n    if SEQ_TRES == True: sequential_threshold(t)\n    \n    #validation step\n    if VALIDATION == True:\n        model.eval()     # Optional when not using Model Specific layer\n        for batch, (X,Xdot) in enumerate (val_loader):\n            X.to(device) #per passarlo alla gpu\n            Xdot.to(device)\n            #forward pass \n            xtilde, xtildedot, z, zdot, zdot_hat = model(X,Xdot)\n            # validation loss \n            loss, _ = model.loss_function(X, Xdot, xtilde, xtildedot, zdot, zdot_hat,model.XI)\n            loss_val_epoch.append(loss.item())\n            del  xtilde, xtildedot, z, zdot, zdot_hat,loss\n        \n        loss_val_list.append(sum(loss_val_epoch)/len(loss_val_epoch))\n\n    #end = time.time()\n    if t % 20 == 0:\n        print()\n        print(f\"Epoch {t}\\n-------------------------------\")\n        for key in loss_list.keys():\n            temp = loss_list[key]\n            print(f'{key} of epoch {t}: {temp[-1]:.3e}')\n        print(f'val loss of epoch {t}: {loss_val_list[-1]:.3e}')\n        #print('time: ',end-start)\n        \n    if SAVE == True:\n        if t % 100 ==0 and t>1 and loss_val_list[t] < loss_val_list[t-1]:\n            f1 = './model'+str(batch_size)+'_'+str(t)+'epochs'+'.pt'\n            torch.save(model,f1)\n            print('salvato il',f1)\n\nprint(\"Done!\")\ntorch.save(model,'./model.pt')\n","metadata":{"id":"1vtgRajRvOZK","execution":{"iopub.status.busy":"2021-12-21T17:46:07.479978Z","iopub.execute_input":"2021-12-21T17:46:07.480305Z","iopub.status.idle":"2021-12-21T17:54:54.614551Z","shell.execute_reply.started":"2021-12-21T17:46:07.480268Z","shell.execute_reply":"2021-12-21T17:54:54.612085Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_model()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:55:17.123406Z","iopub.execute_input":"2021-12-21T17:55:17.123655Z","iopub.status.idle":"2021-12-21T17:55:17.136549Z","shell.execute_reply.started":"2021-12-21T17:55:17.123627Z","shell.execute_reply":"2021-12-21T17:55:17.135595Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"model = torch.load(model,'./model'+str(batch_size)+'100_epochs'+'.pt')","metadata":{"id":"S9h_nzTmWS6t","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### loss 8192 100 epochs\nrecon_loss of epoch 99: 85.203\nsindy_loss_x of epoch 99: 3025.53\nsindy_loss_z of epoch 99: 46474.64\nsindy_regular_loss of epoch 99: 14.79\ntot of epoch 99: 89.040\n\n### loss con 1024 bs 100 epochs\nrecon_loss of epoch 99: 7.975912475585938\nsindy_loss_x of epoch 99: 1166.713880266462\nsindy_loss_z of epoch 99: 16406.63359375\nsindy_regular_loss of epoch 99: 12.32967277935573\ntot of epoch 99: 9.379724172183446\n\n### loss con 256 batchsize 100 epochs\nrecon_loss of epoch 99: 22.13456918171474\nsindy_loss_x of epoch 99: 738.3788791111538\nsindy_loss_z of epoch 99: 31111.867034040177\nsindy_regular_loss of epoch 99: 9.434283091340745\ntot of epoch 99: 24.059446038518633\n\n\nconclusione la miglior batchsize sembra essere 1024 !\n","metadata":{"id":"yty_2F0kKbKn"}},{"cell_type":"code","source":"import pandas as pd\ndata = pd.DataFrame.from_dict(loss_list)\ndata.to_csv('./data'+str(batch_size)+'_'+str(t)+'epochs'+'.csv')\ntorch.save(model,'./model'+str(batch_size)+'.pt')\nfor key in loss_list.keys():\n    plt.plot(loss_list[key],label = key)\nplt.plot(loss_val_list,label = 'validation')    \nplt.legend(loc = 'best')\nplt.title('Loss con batch size di '+str(batch_size))\n","metadata":{"id":"EK0Knpr4BEb-","outputId":"d14b5ec0-8037-4838-e503-99dee6d981eb","execution":{"iopub.status.busy":"2021-12-21T17:30:14.168604Z","iopub.execute_input":"2021-12-21T17:30:14.169065Z","iopub.status.idle":"2021-12-21T17:30:14.480237Z","shell.execute_reply.started":"2021-12-21T17:30:14.169009Z","shell.execute_reply":"2021-12-21T17:30:14.479564Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"plt.semilogy(loss_val_list)\nplt.semilogy(loss_list['tot'])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:15:36.642161Z","iopub.execute_input":"2021-12-21T17:15:36.642426Z","iopub.status.idle":"2021-12-21T17:15:37.209756Z","shell.execute_reply.started":"2021-12-21T17:15:36.642395Z","shell.execute_reply":"2021-12-21T17:15:37.209096Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"plt.semilogy(loss_list['tot'])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T14:42:40.780151Z","iopub.execute_input":"2021-12-21T14:42:40.780695Z","iopub.status.idle":"2021-12-21T14:42:41.16906Z","shell.execute_reply.started":"2021-12-21T14:42:40.780659Z","shell.execute_reply":"2021-12-21T14:42:41.168364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_list = model.SINDyLibrary.get_feature_names()\n","metadata":{"id":"_gJS_yUTKbKn","outputId":"71ac9bb5-5ae8-4eea-8b8a-545c57b7aac0","execution":{"iopub.status.busy":"2021-12-21T17:45:50.686848Z","iopub.execute_input":"2021-12-21T17:45:50.687390Z","iopub.status.idle":"2021-12-21T17:45:50.692317Z","shell.execute_reply.started":"2021-12-21T17:45:50.687352Z","shell.execute_reply":"2021-12-21T17:45:50.690344Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"coefficient_mask = model.XI_coefficient_mask.cpu().detach().numpy()\n","metadata":{"id":"61PhjfffFRpV","outputId":"c872d124-2be1-4596-bc2c-26c1ddf9e600","execution":{"iopub.status.busy":"2021-12-21T17:36:23.328096Z","iopub.execute_input":"2021-12-21T17:36:23.328834Z","iopub.status.idle":"2021-12-21T17:36:23.335789Z","shell.execute_reply.started":"2021-12-21T17:36:23.328795Z","shell.execute_reply":"2021-12-21T17:36:23.333080Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"XI = model.XI.cpu().detach().numpy()","metadata":{"id":"5z-yuKxcFJZY","outputId":"98fd3495-44c9-4dcb-d3bf-1d7e3ffe272c","execution":{"iopub.status.busy":"2021-12-21T17:36:18.472233Z","iopub.execute_input":"2021-12-21T17:36:18.472499Z","iopub.status.idle":"2021-12-21T17:36:18.477078Z","shell.execute_reply.started":"2021-12-21T17:36:18.472467Z","shell.execute_reply":"2021-12-21T17:36:18.476318Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"for i in range(latent_dim-1):\n    print(i)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:38:04.691944Z","iopub.execute_input":"2021-12-21T17:38:04.692214Z","iopub.status.idle":"2021-12-21T17:38:04.698145Z","shell.execute_reply.started":"2021-12-21T17:38:04.692183Z","shell.execute_reply":"2021-12-21T17:38:04.697401Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"XI.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:39:18.179406Z","iopub.execute_input":"2021-12-21T17:39:18.179674Z","iopub.status.idle":"2021-12-21T17:39:18.185554Z","shell.execute_reply.started":"2021-12-21T17:39:18.179644Z","shell.execute_reply":"2021-12-21T17:39:18.184723Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"coefficient_mask[0:4]","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:45:09.210263Z","iopub.execute_input":"2021-12-21T17:45:09.210726Z","iopub.status.idle":"2021-12-21T17:45:09.215595Z","shell.execute_reply.started":"2021-12-21T17:45:09.210689Z","shell.execute_reply":"2021-12-21T17:45:09.214944Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"len(feature_list)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:40:09.804666Z","iopub.execute_input":"2021-12-21T17:40:09.804913Z","iopub.status.idle":"2021-12-21T17:40:09.809819Z","shell.execute_reply.started":"2021-12-21T17:40:09.804885Z","shell.execute_reply":"2021-12-21T17:40:09.809089Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"for i in range(len(feature_list)-1):\n    for j in range(latent_dim-1):\n        coeff = XI[i][j] * coefficient_mask[i][j]\n        if  coeff !=0:\n            print(f\"z{j} = {coeff:.4f} {feature_list[i]}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:44:36.733384Z","iopub.execute_input":"2021-12-21T17:44:36.733652Z","iopub.status.idle":"2021-12-21T17:44:36.748815Z","shell.execute_reply.started":"2021-12-21T17:44:36.733614Z","shell.execute_reply":"2021-12-21T17:44:36.746445Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"x_train = X[29].reshape(1,2601)\nxdot_train = Xdot[29].reshape(1,2601)\nx_train.shape,xdot_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#x_train.to(device) #per passarlo alla gpu\n#xdot_train.to(device)\n#forward pass\nmodel.eval()\n\nxtilde, xtildedot, z, zdot, zdot_hat = model(x_train,xdot_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xtilde.shape, xtildedot.shape, z.shape, zdot.shape, zdot_hat.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(xtilde.reshape(51,51).cpu().detach().numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(xtildedot.reshape(51,51).cpu().detach().numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.multiply(model.XI.cpu().detach().numpy(),model.XI_coefficient_mask.cpu().detach().numpy())","metadata":{"id":"X8ZotQmcpyX0","outputId":"32851d09-1787-46c6-99c8-df815cef4e48"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"k0pGzaxkqE5z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# idee sul plotting\nquello che potrei fare é stampare il recupero della dinamica a seconda delle epoche di training","metadata":{"id":"26rUdKvHYVp9"}},{"cell_type":"code","source":"sl = SINDyNumpy(latent_dim=latent_dim,\n            include_biases=False,\n            include_states=True,\n            include_sin=True,\n            include_cos=True,\n            include_multiply_pairs=False,\n            poly_order=2,\n            include_sqrt=True,\n            include_inverse=False,\n            include_sign_sqrt_of_diff=False)","metadata":{"id":"sXk4xSPHrpUE","execution":{"iopub.status.busy":"2021-12-21T17:22:35.536063Z","iopub.execute_input":"2021-12-21T17:22:35.536510Z","iopub.status.idle":"2021-12-21T17:22:35.541660Z","shell.execute_reply.started":"2021-12-21T17:22:35.536473Z","shell.execute_reply":"2021-12-21T17:22:35.540720Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"from scipy.integrate import odeint\n\ndef pend(y, t,):\n    theta, omega = y\n    dydt = [omega, - np.sin(theta)]\n    return dydt\n\ndef recon_manuale(y,t):\n    z0, z1 = y\n    dydt = [0.00584*z0**3 + 0.00653*z1**3 ,0.0105* z1**3 + 0.0120*z0**3]\n    return dydt\n\ndef recon_auto(y,t):\n    n = latent_dim\n    theta = sl.transform(y.reshape((1,-1))) \n    #theta = sl.transform(y) \n\n    prod = np.matmul(theta,model.XI)\n    return prod.reshape((n,))\n\ndef simulate(f,y0):\n    ta = 0.\n    tb = 10.\n    dt = 0.1 \n    t = np.arange(ta, tb ,dt)\n    \n    \n    sol = odeint(f, y0,t)\n    theta = sol[:,0]\n    omega = sol[:,1]\n    plt.plot(t,theta)\n    plt.plot(t,omega)\n    plt.plot(theta,omega)","metadata":{"id":"hjGUEPpIKbKp","execution":{"iopub.status.busy":"2021-12-21T17:22:36.484950Z","iopub.execute_input":"2021-12-21T17:22:36.485511Z","iopub.status.idle":"2021-12-21T17:22:36.496470Z","shell.execute_reply.started":"2021-12-21T17:22:36.485471Z","shell.execute_reply":"2021-12-21T17:22:36.495712Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"simulate(recon_manuale,[0.5,0.5])","metadata":{"id":"AyGbJv9uKbKr","outputId":"9106f0c7-5871-4c8b-8a77-1c8f425614fd","execution":{"iopub.status.busy":"2021-12-21T17:22:37.034681Z","iopub.execute_input":"2021-12-21T17:22:37.035284Z","iopub.status.idle":"2021-12-21T17:22:37.231819Z","shell.execute_reply.started":"2021-12-21T17:22:37.035244Z","shell.execute_reply":"2021-12-21T17:22:37.229621Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"simulate(recon_auto,[0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5])","metadata":{"id":"obfRKpKazrna","outputId":"3860ada2-8443-4fc9-8b38-4ceb22b1618c","execution":{"iopub.status.busy":"2021-12-21T17:22:37.272576Z","iopub.execute_input":"2021-12-21T17:22:37.273137Z","iopub.status.idle":"2021-12-21T17:22:37.308062Z","shell.execute_reply.started":"2021-12-21T17:22:37.273105Z","shell.execute_reply":"2021-12-21T17:22:37.306761Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"simulate(pend,[0.5,0.5])","metadata":{"id":"xu4WqRLqXyY9","outputId":"0480c3aa-ad8b-472d-866a-fbbdf4e90a20"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"26HW69W2XyWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"3rAQq7zKXyTc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simulate_torch(recon,[0.5,0.5])","metadata":{"id":"BkbHkgIDKbKq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def simulate_torch(f,y0):\n    ta = 0.\n    tb = 10.\n    dt = 0.1 \n    t = torch.arange(ta, tb ,dt)\n    \n    #y0 = [ics[idx][0], ics[idx][1]]\n    sol = odeint(f, y0,t)\n    theta = sol[:,0]\n    omega = sol[:,1]\n    plt.plot(t,theta)","metadata":{"id":"cmRiq82-KbKq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"cYVKkPH9KbKq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simulate(pend,[0.5,0.5])","metadata":{"id":"NteNPuMgKbKq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# plotting ","metadata":{"id":"hwba4c-em6dS"}},{"cell_type":"code","source":"x = X[:,:,0]\nx.shape\n","metadata":{"id":"K96cKeIluSUd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = X[1][:,0]\ny = X[2][:,1]\nz = X[3][:,2]","metadata":{"id":"WI2-nbvzj-fh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xdot = Xdot[1][:,0]\nydot = Xdot[2][:,1]\nzdot = Xdot[3][:,2]","metadata":{"id":"8accQ15cpQVh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig1 = plt.figure(figsize=(10,10))\nax1 = fig1.add_subplot(111, projection='3d')\nax1.plot(x,y,z,linewidth=2)\nax1.view_init(azim=120)","metadata":{"id":"anQRvsmTc9QT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig1 = plt.figure(figsize=(18,6))\nax1 = fig1.add_subplot(131)\nax1.plot(t,x)\nax1.plot(t,xdot,'r')\n\nax2 = fig1.add_subplot(132)\nax2.plot(t,y)\nax2.plot(t,ydot,'r')\n\n\nax3 = fig1.add_subplot(133)\nax3.plot(t,z)\nax3.plot(t,zdot,'r')\n","metadata":{"id":"m8FIHJMMgwTc"},"execution_count":null,"outputs":[]}]}