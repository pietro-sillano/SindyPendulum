{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TO DO LIST\n\n11. capire come fare una prediction con quanto ottenuto\n14. devo usare il test e validation set? si come? vedere l autoencoder come si comporta con dati non visti ?\n15. aggiungere un early stopping\n16. ???\n\n","metadata":{"id":"evH6sjsxsKWE"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n#from torchsummary import summary\n\nimport numpy as np\n\nimport sys\nsyspath = 'SindyPendulum/'\nif syspath not in sys.path:\n    sys.path.append(syspath)","metadata":{"id":"trlxwPDloKs5","execution":{"iopub.status.busy":"2021-12-17T20:30:57.222464Z","iopub.execute_input":"2021-12-17T20:30:57.223394Z","iopub.status.idle":"2021-12-17T20:30:59.034903Z","shell.execute_reply.started":"2021-12-17T20:30:57.223357Z","shell.execute_reply":"2021-12-17T20:30:59.033886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get cpu or gpu device for training.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using {} device\".format(device))","metadata":{"id":"qNbEXw0Uo3zR","outputId":"4e616a81-784a-4444-df87-cfc307a7539c","execution":{"iopub.status.busy":"2021-12-17T20:30:59.037423Z","iopub.execute_input":"2021-12-17T20:30:59.037826Z","iopub.status.idle":"2021-12-17T20:30:59.091153Z","shell.execute_reply.started":"2021-12-17T20:30:59.037783Z","shell.execute_reply":"2021-12-17T20:30:59.088129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Generation","metadata":{"id":"8VneYLUfl5bz"}},{"cell_type":"code","source":"!git clone https://github.com/pietro-sillano/SindyPendulum.git","metadata":{"id":"ojotcMcmDoRF","outputId":"ca12eb4f-4e7d-487e-950e-b3cecc6f8791","execution":{"iopub.status.busy":"2021-12-17T20:30:59.18347Z","iopub.execute_input":"2021-12-17T20:30:59.184052Z","iopub.status.idle":"2021-12-17T20:31:00.927879Z","shell.execute_reply.started":"2021-12-17T20:30:59.184017Z","shell.execute_reply":"2021-12-17T20:31:00.926716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd SindyPendulum && git pull","metadata":{"id":"jiqk7akK2aoa","outputId":"13690084-78c4-4cde-f1ad-53e833a5f44e","execution":{"iopub.status.busy":"2021-12-17T20:31:00.930707Z","iopub.execute_input":"2021-12-17T20:31:00.931066Z","iopub.status.idle":"2021-12-17T20:31:02.160613Z","shell.execute_reply.started":"2021-12-17T20:31:00.931017Z","shell.execute_reply":"2021-12-17T20:31:02.159433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"afRdAZnLIC-O"}},{"cell_type":"code","source":"from sindy_library import SINDyLibrary","metadata":{"execution":{"iopub.status.busy":"2021-12-17T20:31:02.163374Z","iopub.execute_input":"2021-12-17T20:31:02.163774Z","iopub.status.idle":"2021-12-17T20:31:02.173598Z","shell.execute_reply.started":"2021-12-17T20:31:02.16372Z","shell.execute_reply":"2021-12-17T20:31:02.172566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!python SindyPendulum/lorentz.py  -i 1000","metadata":{"execution":{"iopub.status.busy":"2021-12-17T20:31:02.17716Z","iopub.execute_input":"2021-12-17T20:31:02.177824Z","iopub.status.idle":"2021-12-17T20:31:02.183099Z","shell.execute_reply.started":"2021-12-17T20:31:02.177775Z","shell.execute_reply":"2021-12-17T20:31:02.182027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python SindyPendulum/data_pendulum_image.py  -i 100","metadata":{"id":"d1DKMT2rsJPt","outputId":"940c1b3d-85e7-453c-83db-78e2485fd128","execution":{"iopub.status.busy":"2021-12-17T20:31:02.185619Z","iopub.execute_input":"2021-12-17T20:31:02.186541Z","iopub.status.idle":"2021-12-17T20:33:52.081098Z","shell.execute_reply.started":"2021-12-17T20:31:02.186492Z","shell.execute_reply":"2021-12-17T20:33:52.079946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.load('X.npy')\nXdot = np.load('Xdot.npy')\n\nX = torch.from_numpy(X).float().to(device)\nXdot = torch.from_numpy(Xdot).float().to(device)\nX.shape, Xdot.shape","metadata":{"id":"GUIqs9cQNktG","outputId":"9700b864-88fa-4437-e482-e71033912aaf","execution":{"iopub.status.busy":"2021-12-17T20:33:52.083936Z","iopub.execute_input":"2021-12-17T20:33:52.0842Z","iopub.status.idle":"2021-12-17T20:34:07.692684Z","shell.execute_reply.started":"2021-12-17T20:33:52.084165Z","shell.execute_reply":"2021-12-17T20:34:07.691635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 1024\nmy_dataset = TensorDataset(X,Xdot)\ndataloader = DataLoader(my_dataset,batch_size=batch_size, shuffle=True)","metadata":{"id":"B2vYJ447_sxQ","execution":{"iopub.status.busy":"2021-12-17T20:34:07.695984Z","iopub.execute_input":"2021-12-17T20:34:07.696343Z","iopub.status.idle":"2021-12-17T20:34:07.702529Z","shell.execute_reply.started":"2021-12-17T20:34:07.696298Z","shell.execute_reply":"2021-12-17T20:34:07.701304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Network\n\n\n","metadata":{"id":"9lRG3Ea4CWWl"}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_size,latent_dim):\n        super(Encoder, self).__init__()\n        self.fc1 = nn.Linear(input_size,512)\n        self.fc2 = nn.Linear(512,128)\n        self.fc3 = nn.Linear(128,64)\n        self.fc4 = nn.Linear(64,latent_dim)\n        self.initialize_weights()\n\n    def initialize_weights(self):\n        for m in self.modules():\n            print(m)\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        #x = torch.sigmoid(self.fc1(x))\n        \n        #x = torch.sigmoid(self.fc2(x))\n        #x = torch.sigmoid(self.fc3(x))   \n        #x = torch.sigmoid(self.fc4(x))\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = torch.relu(self.fc3(x))   \n        x = torch.relu(self.fc4(x))\n        return x \n\nclass Decoder(nn.Module):\n    def __init__(self, input_size,latent_dim):\n        super(Decoder, self).__init__()\n        self.fc1 = nn.Linear(latent_dim,64)\n        self.fc2 = nn.Linear(64,128)\n        self.fc3 = nn.Linear(128,512)\n        self.fc4 = nn.Linear(512,input_size)\n        self.initialize_weights()\n\n    def forward(self, x):\n        #x = torch.sigmoid(self.fc1(x))\n        #x = torch.sigmoid(self.fc2(x))\n        #x = torch.sigmoid(self.fc3(x))   \n        #x = torch.sigmoid(self.fc4(x))\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = torch.relu(self.fc3(x))   \n        x = torch.relu(self.fc4(x))\n        return x\n\n    def initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_normal_(m.weight)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n\nclass Autoencoder(nn.Module):\n    def __init__(self, input_size, latent_dim):\n        super(Autoencoder, self).__init__()\n        self.encoder = Encoder(input_size,latent_dim)\n        self.decoder = Decoder(input_size,latent_dim)\n        self.SINDyLibrary = SINDyLibrary(\n            device=device,\n            latent_dim=latent_dim,\n            include_biases=False,\n            include_states=True,\n            include_sin=True,\n            include_cos=True,\n            include_multiply_pairs=True,\n            poly_order=3,\n            include_sqrt=True,\n            include_inverse=False,\n            include_sign_sqrt_of_diff=False)\n        \n#        self.XI = nn.Parameter(torch.full((self.SINDyLibrary.number_candidate_functions,latent_dim), 0.1,dtype = torch.float32,requires_grad=True,device = device))\n        self.XI = nn.Parameter(torch.full((self.SINDyLibrary.number_candidate_functions,latent_dim), 0.5,dtype = torch.float32,requires_grad=True,device = device))\n\n        self.XI_coefficient_mask = torch.ones((self.SINDyLibrary.number_candidate_functions,latent_dim),dtype = torch.float32, device=device)\n\n    def configure_optimizers(self):\n        learning_rate = 1e-4\n#        return torch.optim.SGD(self.parameters(), lr=learning_rate)\n        return torch.optim.Adam(self.parameters(), lr=learning_rate)\n\n\n    def t_derivative(self,input, xdot, weights, biases, activation='sigmoid'):\n        \"\"\"\n        Compute the first order time derivatives by propagating through the network.\n        da[l]dt = xdot * da[l]dx = xdot * product(g'(w[l]a[l-1] + b[l])* w[l])\n        Arguments:\n            input - 2D tensorflow array, input to the network. Dimensions are number of time points\n            by number of state variables.\n            xdot - First order time derivatives of the input to the network. quello che conosciamo\n            weights - List of tensorflow arrays containing the network weights\n            biases - List of tensorflow arrays containing the network biases\n            activation - String specifying which activation function to use. Options are\n            'elu' (exponential linear unit), 'relu' (rectified linear unit), 'sigmoid',\n            or linear.\n\n        Returns:\n            dadt - Tensorflow array, first order time derivatives of the network output.\n        \"\"\"\n        a   = input\n        dadt = xdot #per le condizioni iniziali\n\n        if activation == 'sigmoid':\n            for i in range(len(weights) - 1):\n                z = torch.matmul(a, weights[i].T) + biases[i]\n                a = torch.sigmoid(z)\n                gprime = a * (1-a)\n                dadt = gprime * torch.matmul(dadt, weights[i].T)\n            dadt = torch.matmul(dadt, weights[-1].T) #fuori dal ciclo bisogna ancora moltiplicare per i pesi dell ultimo livello\n            \n        elif activation == 'relu':\n            for i in range(len(weights) - 1):\n                #print('modulo n ',i)\n                #print('weights',weights[i].shape)\n                z = torch.matmul(a, weights[i].T) + biases[i]\n                #print('z:',z.shape)\n                a = torch.relu(z)\n                #print('a:',a.shape)\n                dadt = (z > 0).float() * torch.matmul(dadt, weights[i].T)    \n            dadt = torch.matmul(dadt, weights[-1].T) #fuori dal ciclo bisogna ancora moltiplicare per i pesi dell ultimo livello\n            #print(dadt)\n        return dadt #nel caso che ci serve dadt sarÃ¡ l output dell encoder ossia le latent variables!\n\n    \n    \n    def compute_quantities(self,x,xdot):\n    \n        z = self.encoder(x)\n        xtilde = self.decoder(z)\n\n        theta = self.SINDyLibrary.transform(z) \n        zdot_hat = torch.matmul(theta, self.XI_coefficient_mask * self.XI)\n        \n        encoder_parameters = list(self.encoder.parameters())\n        encoder_weight_list = [w for w in encoder_parameters if len(w.shape) == 2]\n        encoder_biases_list = [b for b in encoder_parameters if len(b.shape) == 1]\n        zdot = self.t_derivative(x, xdot, encoder_weight_list, encoder_biases_list, activation='relu')                                               \n\n        #print(\"propagazione sul decoder\")\n        decoder_parameters = list(self.decoder.parameters())\n        decoder_weight_list = [w for w in decoder_parameters if len(w.shape) == 2]\n        decoder_biases_list = [b for b in decoder_parameters if len(b.shape) == 1]\n        xtildedot = self.t_derivative(z, zdot_hat, decoder_weight_list, decoder_biases_list, activation='relu')    \n        \n        if(DEBUG == True):\n            print('z',z)\n            print(' xtilde',xtilde)\n            print('theta',theta)\n            print('max theta',theta.max())\n            print('zdot',zdot)\n            print('zdothat',zdot_hat)\n            print('xtildedot',xtildedot)\n\n\n        return xtilde, xtildedot, z, zdot, zdot_hat\n\n    def loss_function(self, x, xdot, xtilde, xtildedot, zdot, zdot_hat,XI):\n        mse = nn.MSELoss()\n        alpha1 = 5e-4\n        alpha2 = 5e-5\n        alpha3 = 1e-5\n        loss = {}\n        loss['recon_loss'] = mse(x, xtilde) #errore di ricostruzione \n        loss ['sindy_loss_x'] = mse(xdot, xtildedot) \n        loss ['sindy_loss_z'] = mse(zdot, zdot_hat) \n        loss['sindy_regular_loss'] = torch.sum(torch.abs(XI)) #norma L1 degli XI\n        loss['tot'] = loss['recon_loss'] + alpha1*loss['sindy_loss_x'] + alpha2*loss['sindy_loss_z'] + alpha3*loss['sindy_regular_loss']\n        tot = loss['tot']\n        return tot, loss\n    \n    def forward(self, x, xdot):\n        return self.compute_quantities(x, xdot)","metadata":{"id":"5ZSdKOTO8dFN","execution":{"iopub.status.busy":"2021-12-17T20:34:07.704619Z","iopub.execute_input":"2021-12-17T20:34:07.704998Z","iopub.status.idle":"2021-12-17T20:34:13.366627Z","shell.execute_reply.started":"2021-12-17T20:34:07.704954Z","shell.execute_reply":"2021-12-17T20:34:13.365258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_size = X.shape[1]\nlatent_dim = 2\n","metadata":{"id":"c4mBzZuzxPYP","execution":{"iopub.status.busy":"2021-12-17T20:34:13.368275Z","iopub.execute_input":"2021-12-17T20:34:13.369293Z","iopub.status.idle":"2021-12-17T20:34:17.904787Z","shell.execute_reply.started":"2021-12-17T20:34:13.369246Z","shell.execute_reply":"2021-12-17T20:34:17.9036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Autoencoder(input_size,latent_dim).to(device)","metadata":{"id":"sOuh7zJeoRmH","execution":{"iopub.status.busy":"2021-12-17T20:34:17.906411Z","iopub.execute_input":"2021-12-17T20:34:17.906833Z","iopub.status.idle":"2021-12-17T20:34:18.010524Z","shell.execute_reply.started":"2021-12-17T20:34:17.906787Z","shell.execute_reply":"2021-12-17T20:34:18.009339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.load('/model.pt')","metadata":{"id":"UgJbXsnO_-U1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.SINDyLibrary.number_candidate_functions","metadata":{"id":"8r_OGkXz2Mgl","outputId":"ed669b0d-cfb4-42c2-fe3b-54a8264569bb","execution":{"iopub.status.busy":"2021-12-17T20:34:18.012467Z","iopub.execute_input":"2021-12-17T20:34:18.012868Z","iopub.status.idle":"2021-12-17T20:34:18.021832Z","shell.execute_reply.started":"2021-12-17T20:34:18.012767Z","shell.execute_reply":"2021-12-17T20:34:18.020183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parameters and Training\n","metadata":{"id":"6ZqwZy2XmMum"}},{"cell_type":"code","source":"def sequential_threshold(t):\n    if t % 50 == 0:\n        model.XI_coefficient_mask = torch.abs(model.XI) > 0.1\n        print(model.XI_coefficient_mask)","metadata":{"id":"zrBLCBxXTPaa","execution":{"iopub.status.busy":"2021-12-17T20:34:18.024101Z","iopub.execute_input":"2021-12-17T20:34:18.025019Z","iopub.status.idle":"2021-12-17T20:34:18.032363Z","shell.execute_reply.started":"2021-12-17T20:34:18.02497Z","shell.execute_reply":"2021-12-17T20:34:18.030921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport multiprocessing\n\nmem_bytes = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')  # e.g. 4015976448\nmem_gib = mem_bytes/(1024.**3)  # e.g. 3.74\nprint(\"RAM: %f GB\" % mem_gib)\nprint(\"CORES: %d\" % multiprocessing.cpu_count())","metadata":{"execution":{"iopub.status.busy":"2021-12-17T20:34:18.034881Z","iopub.execute_input":"2021-12-17T20:34:18.035603Z","iopub.status.idle":"2021-12-17T20:34:18.047103Z","shell.execute_reply.started":"2021-12-17T20:34:18.035558Z","shell.execute_reply":"2021-12-17T20:34:18.04564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 1000\nDEBUG = False\n\n\nfor t in range(epochs):\n\n    size = len(dataloader.dataset)\n    model.train()\n    \n    #queste serve per le loss di ogni batch\n    loss_epoch = {}\n    loss_epoch['recon_loss'] = []\n    loss_epoch['sindy_loss_x'] = []\n    loss_epoch['sindy_loss_z'] = []\n    loss_epoch['sindy_regular_loss'] = []\n    loss_epoch['tot'] = []\n    \n    \n    for batch, (X,Xdot) in enumerate (dataloader):\n        X.to(device) #per passarlo alla gpu\n        Xdot.to(device)\n        #forward pass \n        xtilde, xtildedot, z, zdot, zdot_hat = model(X,Xdot)\n\n        # Backpropagation\n        optimizer = model.configure_optimizers()\n        loss, loss_dict = model.loss_function(X, Xdot, xtilde, xtildedot, zdot, zdot_hat,model.XI)\n        loss.backward()\n        del  xtilde, xtildedot, z, zdot, zdot_hat,loss\n        optimizer.step()\n        optimizer.zero_grad()\n\n        current = batch * len(X)\n\n        for key in loss_epoch.keys():\n            loss_epoch[key].append(loss_dict[key].item())\n        del loss_dict\n\n    for key in loss_epoch.keys():\n        loss_list[key].append(sum(loss_epoch[key])/len(loss_epoch[key]))\n    del loss_epoch\n    \n\n    if t % 5 == 0:\n        print()\n        print(f\"Epoch {t}\\n-------------------------------\")\n        for key in loss_list.keys():\n            temp = loss_list[key]\n            print(f'{key} of epoch {t}: {temp[-1]}')\n       # print(f'mean loss of epoch {t}: {temp[t]}')\n    \n    \n    sequential_threshold(t)\nif(t % round(t*0.1) == 0):\n    torch.save(model,'./model'+str(batch_size)+t+'epochs'+'.pt')\n\nprint(\"Done!\")\ntorch.save(model,'./model.pt')\n","metadata":{"id":"1vtgRajRvOZK","outputId":"f3bce58e-0369-4db7-e120-95bbc3170f14","execution":{"iopub.status.busy":"2021-12-17T20:34:18.053207Z","iopub.execute_input":"2021-12-17T20:34:18.053565Z","iopub.status.idle":"2021-12-17T20:34:29.607917Z","shell.execute_reply.started":"2021-12-17T20:34:18.053518Z","shell.execute_reply":"2021-12-17T20:34:29.606538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"e4mK6WodC0sm"}},{"cell_type":"code","source":"model.SINDyLibrary.get_feature_names()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### loss 8192 100 epochs\nrecon_loss of epoch 99: 85.203\nsindy_loss_x of epoch 99: 3025.53\nsindy_loss_z of epoch 99: 46474.64\nsindy_regular_loss of epoch 99: 14.79\ntot of epoch 99: 89.040\n\n### loss con 1024 bs 100 epochs\nrecon_loss of epoch 99: 7.975912475585938\nsindy_loss_x of epoch 99: 1166.713880266462\nsindy_loss_z of epoch 99: 16406.63359375\nsindy_regular_loss of epoch 99: 12.32967277935573\ntot of epoch 99: 9.379724172183446\n\n### loss con 256 batchsize 100 epochs\nrecon_loss of epoch 99: 22.13456918171474\nsindy_loss_x of epoch 99: 738.3788791111538\nsindy_loss_z of epoch 99: 31111.867034040177\nsindy_regular_loss of epoch 99: 9.434283091340745\ntot of epoch 99: 24.059446038518633\n\n\nconclusione la miglior batchsize sembra essere 1024 !\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndata = pd.DataFrame.from_dict(loss_list)\ndata.to_csv('./data'+str(batch_size)+'.csv')\ntorch.save(model,'./model'+str(batch_size)+'.pt')\nfor key in loss_list.keys():\n    plt.plot(loss_list[key],label = key)\n    plt.legend(loc = 'best')\n    plt.title('con batch size di'+str(batch_size))","metadata":{"id":"EK0Knpr4BEb-","outputId":"bd96bec2-5a0a-4ed4-db26-04867ccb377c","execution":{"iopub.status.busy":"2021-12-13T22:49:40.520571Z","iopub.execute_input":"2021-12-13T22:49:40.521013Z","iopub.status.idle":"2021-12-13T22:49:40.82057Z","shell.execute_reply.started":"2021-12-13T22:49:40.520976Z","shell.execute_reply":"2021-12-13T22:49:40.819731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_list['sindy_regular_loss']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.XI","metadata":{"id":"5z-yuKxcFJZY","outputId":"6bdccd5d-6701-4ec0-ddde-da881965f49d","execution":{"iopub.status.busy":"2021-12-13T22:28:39.116892Z","iopub.execute_input":"2021-12-13T22:28:39.117769Z","iopub.status.idle":"2021-12-13T22:28:39.143066Z","shell.execute_reply.started":"2021-12-13T22:28:39.117712Z","shell.execute_reply":"2021-12-13T22:28:39.142308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.XI_coefficient_mask","metadata":{"id":"61PhjfffFRpV","outputId":"6b9b6f6e-2287-42d0-e021-950ae5b89ad3","execution":{"iopub.status.busy":"2021-12-13T22:28:42.581288Z","iopub.execute_input":"2021-12-13T22:28:42.581556Z","iopub.status.idle":"2021-12-13T22:28:42.592345Z","shell.execute_reply.started":"2021-12-13T22:28:42.581527Z","shell.execute_reply":"2021-12-13T22:28:42.591204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.integrate import odeint\n\ndef pend(y, t,):\n    theta, omega = y\n    dydt = [omega, - np.sin(theta)]\n    return dydt\n\ndef recon(y,t):\n    theta = model.SINDyLibrary.transform(y) \n    prod = torch.matmul(theta,model.XI)\n    #prod = prod.numpy()\n    return prod\n\n\ndef simulate(f,y0):\n    ta = 0.\n    tb = 10.\n    dt = 0.1 \n    t = np.arange(ta, tb ,dt)\n    \n    #y0 = [ics[idx][0], ics[idx][1]]\n    sol = odeint(f, y0,t)\n    theta = sol[:,0]\n    omega = sol[:,1]\n    plt.plot(t,theta)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def simulate_torch(f,y0):\n    ta = 0.\n    tb = 10.\n    dt = 0.1 \n    t = torch.arange(ta, tb ,dt)\n    \n    #y0 = [ics[idx][0], ics[idx][1]]\n    sol = odeint(f, y0,t)\n    theta = sol[:,0]\n    omega = sol[:,1]\n    plt.plot(t,theta)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simulate_torch(recon,[0.5,0.5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simulate(pend,[0.5,0.5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simulate(recon,[0.5,0.5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# plotting ","metadata":{"id":"hwba4c-em6dS"}},{"cell_type":"code","source":"x = X[:,:,0]\nx.shape\n","metadata":{"id":"K96cKeIluSUd","outputId":"3c8173f9-5aa7-4873-848b-2e8fc182a233","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = X[1][:,0]\ny = X[2][:,1]\nz = X[3][:,2]","metadata":{"id":"WI2-nbvzj-fh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xdot = Xdot[1][:,0]\nydot = Xdot[2][:,1]\nzdot = Xdot[3][:,2]","metadata":{"id":"8accQ15cpQVh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig1 = plt.figure(figsize=(10,10))\nax1 = fig1.add_subplot(111, projection='3d')\nax1.plot(x,y,z,linewidth=2)\nax1.view_init(azim=120)","metadata":{"id":"anQRvsmTc9QT","outputId":"79f01b7a-4fe7-4477-8871-01a93c4e4615","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig1 = plt.figure(figsize=(18,6))\nax1 = fig1.add_subplot(131)\nax1.plot(t,x)\nax1.plot(t,xdot,'r')\n\nax2 = fig1.add_subplot(132)\nax2.plot(t,y)\nax2.plot(t,ydot,'r')\n\n\nax3 = fig1.add_subplot(133)\nax3.plot(t,z)\nax3.plot(t,zdot,'r')\n","metadata":{"id":"m8FIHJMMgwTc","outputId":"9ef6fbb3-68bf-40b5-8210-2e3deb09d9f7","trusted":true},"execution_count":null,"outputs":[]}]}